{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9312f26",
   "metadata": {},
   "source": [
    "# Data scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef4785ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac2f2459",
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.get(\"https://insights.blackcoffer.com/can-robots-tackle-late-life-loneliness/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45f9fa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(req.content, \"html.parser\")\n",
    "res = soup.title\n",
    "paras = soup.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbb256b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this era, everyone is busy in his life. No one spares time for someone. so robots tackle life loneliness? We have no time to stand and stare. This causes loneliness. Loneliness is due to fast-moving life and hurry and worry. In the 21st century, everyone is spending most of their time earning money. They are day-by-day transforming into money-earning machines. Due to his perception, we are losing our relations as we can’t give enough time to our families. They are busy earning their livelihood. They never get satisfies and always want more. Everyone is in a race of earning and then sends his children far away from himself to make them well settled in order to maintain their status. But one faces the consequences of this kind of lifestyle in his old age. People usually don’t spend time with their children when their children are in their childhood but they yearn for the company of their children in their old age. They feel lonely but have none to talk with. They are still attached to people, places, belongings, and memorable events from the past, although they understand that life cannot continue the same way as earlier, and this may easily result in feelings of loneliness and social isolation. As they become older, they need to be attended to in order to meet their daily needs. Robots can indeed serve the purpose but they can aid only mechanical care. They are just emotionless, feeling fewer entities. Robots aren’t creative. They can work only according to a pre-programmed system and till now no such software has been created that can transfer human feelings into robots. This is the major loophole of using robots to tackle late-life loneliness. They can undoubtedly serve their masters but their masters can’t share their feelings with them as they are incapable to understand or react to them. They can’t change their activity according to the occasion. They can provide anything except emotional satisfaction and without emotional gratification, loneliness can’t be tackled. A master can be attached to his robot but that attachment is only due to their service. They can’t share their thoughts with them. In this era, we are rendered lonely and in late- life feel the need for a companion with whom we can talk. We feel a need for someone who can listen to us, react, and advise us to tackle our day-to-day life problems. But we can’t find one. We have, undoubtedly, achieved great progress in terms of technology but we can never fill the void in the heart of a person struggling with his late-life loneliness with our advancements. We are in a kind of mental trance in which we experience fame, progress, wealth, etc. but when we gain our consciousness, we find ourselves lonely in this world. Relations in life are actual wealth in a person’s life. We can never enjoy such a bond with a robot. It will follow our commands, take our appropriate care but can’t react to our emotions. It can’t console us. When a man lives in loneliness for a long time, it eats up his conscience and transforms him into a machine. Robots can never become our friends, crack jokes, weep our tears, or establish an emotional connection with us. They can’t understand our feelings. Many people go into depression. Depression or the occurrence of depressive symptoms is a prominent condition amongst older people, with a significant impact on their well-being and quality of life. They remain sick and loneliness directly impacts longevity. Lonely people often think that they are no longer needed in this world and thus they want to die. It impacts their mental, psychological, social, and physical health. Robots prove to be useless in these matters. They can provide motivation, only if they have the software to do so but can’t, themselves, react to such a situation. They don’t know about anger, happiness, or sadness. They don’t themselves bring food when their master is hungry until commanded to do so. They can’t even offer a glass of water themselves. A man living without relations and without fellow feeling no longer remains a human being. He becomes none less than a machine as, due to his loneliness, he becomes mentally ill and goes into a condition like trauma where he no longer enjoys nature’s blessings, becomes happy or sad as he loses the ability to react and hence can’t act. It’s a dangerous situation. We face a plethora of challenges in assisted living facilities such as not being addressed to emotional needs, being neglected, and forcing a withdrawal from social activities. Relations in life, interaction with fellow beings, sharing of joy and happiness, and fellow feeling make a man from mere a ‘being’ to a ‘social being’ and finally a human being.\n"
     ]
    }
   ],
   "source": [
    "texts = \" \".join([paragraph.text.strip() for paragraph in paras])\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e79f5f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4695"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8f1fcc",
   "metadata": {},
   "source": [
    "Removing Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5285c8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4695"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "texts = re.sub(r'[\\'\\“\\”\\()\\%\\,\\-\\'\\’\\?\\ ]', ' ', texts)\n",
    "texts[0:200]\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fafe7be",
   "metadata": {},
   "source": [
    "# Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "089b8663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "280876b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'this',\n",
       " 'era',\n",
       " 'everyone',\n",
       " 'is',\n",
       " 'busy',\n",
       " 'in',\n",
       " 'his',\n",
       " 'life',\n",
       " '.',\n",
       " 'No',\n",
       " 'one',\n",
       " 'spares',\n",
       " 'time',\n",
       " 'for',\n",
       " 'someone',\n",
       " '.',\n",
       " 'so',\n",
       " 'robots',\n",
       " 'tackle',\n",
       " 'life',\n",
       " 'loneliness',\n",
       " 'We',\n",
       " 'have',\n",
       " 'no',\n",
       " 'time',\n",
       " 'to',\n",
       " 'stand',\n",
       " 'and',\n",
       " 'stare',\n",
       " '.',\n",
       " 'This',\n",
       " 'causes',\n",
       " 'loneliness',\n",
       " '.',\n",
       " 'Loneliness',\n",
       " 'is',\n",
       " 'due',\n",
       " 'to',\n",
       " 'fast',\n",
       " 'moving',\n",
       " 'life',\n",
       " 'and',\n",
       " 'hurry',\n",
       " 'and',\n",
       " 'worry',\n",
       " '.',\n",
       " 'In',\n",
       " 'the',\n",
       " '21st',\n",
       " 'century',\n",
       " 'everyone',\n",
       " 'is',\n",
       " 'spending',\n",
       " 'most',\n",
       " 'of',\n",
       " 'their',\n",
       " 'time',\n",
       " 'earning',\n",
       " 'money',\n",
       " '.',\n",
       " 'They',\n",
       " 'are',\n",
       " 'day',\n",
       " 'by',\n",
       " 'day',\n",
       " 'transforming',\n",
       " 'into',\n",
       " 'money',\n",
       " 'earning',\n",
       " 'machines',\n",
       " '.',\n",
       " 'Due',\n",
       " 'to',\n",
       " 'his',\n",
       " 'perception',\n",
       " 'we',\n",
       " 'are',\n",
       " 'losing',\n",
       " 'our',\n",
       " 'relations',\n",
       " 'as',\n",
       " 'we',\n",
       " 'can',\n",
       " 't',\n",
       " 'give',\n",
       " 'enough',\n",
       " 'time',\n",
       " 'to',\n",
       " 'our',\n",
       " 'families',\n",
       " '.',\n",
       " 'They',\n",
       " 'are',\n",
       " 'busy',\n",
       " 'earning',\n",
       " 'their',\n",
       " 'livelihood',\n",
       " '.',\n",
       " 'They',\n",
       " 'never',\n",
       " 'get',\n",
       " 'satisfies',\n",
       " 'and',\n",
       " 'always',\n",
       " 'want',\n",
       " 'more',\n",
       " '.',\n",
       " 'Everyone',\n",
       " 'is',\n",
       " 'in',\n",
       " 'a',\n",
       " 'race',\n",
       " 'of',\n",
       " 'earning',\n",
       " 'and',\n",
       " 'then',\n",
       " 'sends',\n",
       " 'his',\n",
       " 'children',\n",
       " 'far',\n",
       " 'away',\n",
       " 'from',\n",
       " 'himself',\n",
       " 'to',\n",
       " 'make',\n",
       " 'them',\n",
       " 'well',\n",
       " 'settled',\n",
       " 'in',\n",
       " 'order',\n",
       " 'to',\n",
       " 'maintain',\n",
       " 'their',\n",
       " 'status',\n",
       " '.',\n",
       " 'But',\n",
       " 'one',\n",
       " 'faces',\n",
       " 'the',\n",
       " 'consequences',\n",
       " 'of',\n",
       " 'this',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'lifestyle',\n",
       " 'in',\n",
       " 'his',\n",
       " 'old',\n",
       " 'age',\n",
       " '.',\n",
       " 'People',\n",
       " 'usually',\n",
       " 'don',\n",
       " 't',\n",
       " 'spend',\n",
       " 'time',\n",
       " 'with',\n",
       " 'their',\n",
       " 'children',\n",
       " 'when',\n",
       " 'their',\n",
       " 'children',\n",
       " 'are',\n",
       " 'in',\n",
       " 'their',\n",
       " 'childhood',\n",
       " 'but',\n",
       " 'they',\n",
       " 'yearn',\n",
       " 'for',\n",
       " 'the',\n",
       " 'company',\n",
       " 'of',\n",
       " 'their',\n",
       " 'children',\n",
       " 'in',\n",
       " 'their',\n",
       " 'old',\n",
       " 'age',\n",
       " '.',\n",
       " 'They',\n",
       " 'feel',\n",
       " 'lonely',\n",
       " 'but',\n",
       " 'have',\n",
       " 'none',\n",
       " 'to',\n",
       " 'talk',\n",
       " 'with',\n",
       " '.',\n",
       " 'They',\n",
       " 'are',\n",
       " 'still',\n",
       " 'attached',\n",
       " 'to',\n",
       " 'people',\n",
       " 'places',\n",
       " 'belongings',\n",
       " 'and',\n",
       " 'memorable',\n",
       " 'events',\n",
       " 'from',\n",
       " 'the',\n",
       " 'past',\n",
       " 'although',\n",
       " 'they',\n",
       " 'understand',\n",
       " 'that',\n",
       " 'life',\n",
       " 'can',\n",
       " 'not',\n",
       " 'continue',\n",
       " 'the',\n",
       " 'same',\n",
       " 'way',\n",
       " 'as',\n",
       " 'earlier',\n",
       " 'and',\n",
       " 'this',\n",
       " 'may',\n",
       " 'easily',\n",
       " 'result',\n",
       " 'in',\n",
       " 'feelings',\n",
       " 'of',\n",
       " 'loneliness',\n",
       " 'and',\n",
       " 'social',\n",
       " 'isolation',\n",
       " '.',\n",
       " 'As',\n",
       " 'they',\n",
       " 'become',\n",
       " 'older',\n",
       " 'they',\n",
       " 'need',\n",
       " 'to',\n",
       " 'be',\n",
       " 'attended',\n",
       " 'to',\n",
       " 'in',\n",
       " 'order',\n",
       " 'to',\n",
       " 'meet',\n",
       " 'their',\n",
       " 'daily',\n",
       " 'needs',\n",
       " '.',\n",
       " 'Robots',\n",
       " 'can',\n",
       " 'indeed',\n",
       " 'serve',\n",
       " 'the',\n",
       " 'purpose',\n",
       " 'but',\n",
       " 'they',\n",
       " 'can',\n",
       " 'aid',\n",
       " 'only',\n",
       " 'mechanical',\n",
       " 'care',\n",
       " '.',\n",
       " 'They',\n",
       " 'are',\n",
       " 'just',\n",
       " 'emotionless',\n",
       " 'feeling',\n",
       " 'fewer',\n",
       " 'entities',\n",
       " '.',\n",
       " 'Robots',\n",
       " 'aren',\n",
       " 't',\n",
       " 'creative',\n",
       " '.',\n",
       " 'They',\n",
       " 'can',\n",
       " 'work',\n",
       " 'only',\n",
       " 'according',\n",
       " 'to',\n",
       " 'a',\n",
       " 'pre',\n",
       " 'programmed',\n",
       " 'system',\n",
       " 'and',\n",
       " 'till',\n",
       " 'now',\n",
       " 'no',\n",
       " 'such',\n",
       " 'software',\n",
       " 'has',\n",
       " 'been',\n",
       " 'created',\n",
       " 'that',\n",
       " 'can',\n",
       " 'transfer',\n",
       " 'human',\n",
       " 'feelings',\n",
       " 'into',\n",
       " 'robots',\n",
       " '.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'the',\n",
       " 'major',\n",
       " 'loophole',\n",
       " 'of',\n",
       " 'using',\n",
       " 'robots',\n",
       " 'to',\n",
       " 'tackle',\n",
       " 'late',\n",
       " 'life',\n",
       " 'loneliness',\n",
       " '.',\n",
       " 'They',\n",
       " 'can',\n",
       " 'undoubtedly',\n",
       " 'serve',\n",
       " 'their',\n",
       " 'masters',\n",
       " 'but',\n",
       " 'their',\n",
       " 'masters',\n",
       " 'can',\n",
       " 't',\n",
       " 'share',\n",
       " 'their',\n",
       " 'feelings',\n",
       " 'with',\n",
       " 'them',\n",
       " 'as',\n",
       " 'they',\n",
       " 'are',\n",
       " 'incapable',\n",
       " 'to',\n",
       " 'understand',\n",
       " 'or',\n",
       " 'react',\n",
       " 'to',\n",
       " 'them',\n",
       " '.',\n",
       " 'They',\n",
       " 'can',\n",
       " 't',\n",
       " 'change',\n",
       " 'their',\n",
       " 'activity',\n",
       " 'according',\n",
       " 'to',\n",
       " 'the',\n",
       " 'occasion',\n",
       " '.',\n",
       " 'They',\n",
       " 'can',\n",
       " 'provide',\n",
       " 'anything',\n",
       " 'except',\n",
       " 'emotional',\n",
       " 'satisfaction',\n",
       " 'and',\n",
       " 'without',\n",
       " 'emotional',\n",
       " 'gratification',\n",
       " 'loneliness',\n",
       " 'can',\n",
       " 't',\n",
       " 'be',\n",
       " 'tackled',\n",
       " '.',\n",
       " 'A',\n",
       " 'master',\n",
       " 'can',\n",
       " 'be',\n",
       " 'attached',\n",
       " 'to',\n",
       " 'his',\n",
       " 'robot',\n",
       " 'but',\n",
       " 'that',\n",
       " 'attachment',\n",
       " 'is',\n",
       " 'only',\n",
       " 'due',\n",
       " 'to',\n",
       " 'their',\n",
       " 'service',\n",
       " '.',\n",
       " 'They',\n",
       " 'can',\n",
       " 't',\n",
       " 'share',\n",
       " 'their',\n",
       " 'thoughts',\n",
       " 'with',\n",
       " 'them',\n",
       " '.',\n",
       " 'In',\n",
       " 'this',\n",
       " 'era',\n",
       " 'we',\n",
       " 'are',\n",
       " 'rendered',\n",
       " 'lonely',\n",
       " 'and',\n",
       " 'in',\n",
       " 'late',\n",
       " 'life',\n",
       " 'feel',\n",
       " 'the',\n",
       " 'need',\n",
       " 'for',\n",
       " 'a',\n",
       " 'companion',\n",
       " 'with',\n",
       " 'whom',\n",
       " 'we',\n",
       " 'can',\n",
       " 'talk',\n",
       " '.',\n",
       " 'We',\n",
       " 'feel',\n",
       " 'a',\n",
       " 'need',\n",
       " 'for',\n",
       " 'someone',\n",
       " 'who',\n",
       " 'can',\n",
       " 'listen',\n",
       " 'to',\n",
       " 'us',\n",
       " 'react',\n",
       " 'and',\n",
       " 'advise',\n",
       " 'us',\n",
       " 'to',\n",
       " 'tackle',\n",
       " 'our',\n",
       " 'day',\n",
       " 'to',\n",
       " 'day',\n",
       " 'life',\n",
       " 'problems',\n",
       " '.',\n",
       " 'But',\n",
       " 'we',\n",
       " 'can',\n",
       " 't',\n",
       " 'find',\n",
       " 'one',\n",
       " '.',\n",
       " 'We',\n",
       " 'have',\n",
       " 'undoubtedly',\n",
       " 'achieved',\n",
       " 'great',\n",
       " 'progress',\n",
       " 'in',\n",
       " 'terms',\n",
       " 'of',\n",
       " 'technology',\n",
       " 'but',\n",
       " 'we',\n",
       " 'can',\n",
       " 'never',\n",
       " 'fill',\n",
       " 'the',\n",
       " 'void',\n",
       " 'in',\n",
       " 'the',\n",
       " 'heart',\n",
       " 'of',\n",
       " 'a',\n",
       " 'person',\n",
       " 'struggling',\n",
       " 'with',\n",
       " 'his',\n",
       " 'late',\n",
       " 'life',\n",
       " 'loneliness',\n",
       " 'with',\n",
       " 'our',\n",
       " 'advancements',\n",
       " '.',\n",
       " 'We',\n",
       " 'are',\n",
       " 'in',\n",
       " 'a',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'mental',\n",
       " 'trance',\n",
       " 'in',\n",
       " 'which',\n",
       " 'we',\n",
       " 'experience',\n",
       " 'fame',\n",
       " 'progress',\n",
       " 'wealth',\n",
       " 'etc',\n",
       " '.',\n",
       " 'but',\n",
       " 'when',\n",
       " 'we',\n",
       " 'gain',\n",
       " 'our',\n",
       " 'consciousness',\n",
       " 'we',\n",
       " 'find',\n",
       " 'ourselves',\n",
       " 'lonely',\n",
       " 'in',\n",
       " 'this',\n",
       " 'world',\n",
       " '.',\n",
       " 'Relations',\n",
       " 'in',\n",
       " 'life',\n",
       " 'are',\n",
       " 'actual',\n",
       " 'wealth',\n",
       " 'in',\n",
       " 'a',\n",
       " 'person',\n",
       " 's',\n",
       " 'life',\n",
       " '.',\n",
       " 'We',\n",
       " 'can',\n",
       " 'never',\n",
       " 'enjoy',\n",
       " 'such',\n",
       " 'a',\n",
       " 'bond',\n",
       " 'with',\n",
       " 'a',\n",
       " 'robot',\n",
       " '.',\n",
       " 'It',\n",
       " 'will',\n",
       " 'follow',\n",
       " 'our',\n",
       " 'commands',\n",
       " 'take',\n",
       " 'our',\n",
       " 'appropriate',\n",
       " 'care',\n",
       " 'but',\n",
       " 'can',\n",
       " 't',\n",
       " 'react',\n",
       " 'to',\n",
       " 'our',\n",
       " 'emotions',\n",
       " '.',\n",
       " 'It',\n",
       " 'can',\n",
       " 't',\n",
       " 'console',\n",
       " 'us',\n",
       " '.',\n",
       " 'When',\n",
       " 'a',\n",
       " 'man',\n",
       " 'lives',\n",
       " 'in',\n",
       " 'loneliness',\n",
       " 'for',\n",
       " 'a',\n",
       " 'long',\n",
       " 'time',\n",
       " 'it',\n",
       " 'eats',\n",
       " 'up',\n",
       " 'his',\n",
       " 'conscience',\n",
       " 'and',\n",
       " 'transforms',\n",
       " 'him',\n",
       " 'into',\n",
       " 'a',\n",
       " 'machine',\n",
       " '.',\n",
       " 'Robots',\n",
       " 'can',\n",
       " 'never',\n",
       " 'become',\n",
       " 'our',\n",
       " 'friends',\n",
       " 'crack',\n",
       " 'jokes',\n",
       " 'weep',\n",
       " 'our',\n",
       " 'tears',\n",
       " 'or',\n",
       " 'establish',\n",
       " 'an',\n",
       " 'emotional',\n",
       " 'connection',\n",
       " 'with',\n",
       " 'us',\n",
       " '.',\n",
       " 'They',\n",
       " 'can',\n",
       " 't',\n",
       " 'understand',\n",
       " 'our',\n",
       " 'feelings',\n",
       " '.',\n",
       " 'Many',\n",
       " 'people',\n",
       " 'go',\n",
       " 'into',\n",
       " 'depression',\n",
       " '.',\n",
       " 'Depression',\n",
       " 'or',\n",
       " 'the',\n",
       " 'occurrence',\n",
       " 'of',\n",
       " 'depressive',\n",
       " 'symptoms',\n",
       " 'is',\n",
       " 'a',\n",
       " 'prominent',\n",
       " 'condition',\n",
       " 'amongst',\n",
       " 'older',\n",
       " 'people',\n",
       " 'with',\n",
       " 'a',\n",
       " 'significant',\n",
       " 'impact',\n",
       " 'on',\n",
       " 'their',\n",
       " 'well',\n",
       " 'being',\n",
       " 'and',\n",
       " 'quality',\n",
       " 'of',\n",
       " 'life',\n",
       " '.',\n",
       " 'They',\n",
       " 'remain',\n",
       " 'sick',\n",
       " 'and',\n",
       " 'loneliness',\n",
       " 'directly',\n",
       " 'impacts',\n",
       " 'longevity',\n",
       " '.',\n",
       " 'Lonely',\n",
       " 'people',\n",
       " 'often',\n",
       " 'think',\n",
       " 'that',\n",
       " 'they',\n",
       " 'are',\n",
       " 'no',\n",
       " 'longer',\n",
       " 'needed',\n",
       " 'in',\n",
       " 'this',\n",
       " 'world',\n",
       " 'and',\n",
       " 'thus',\n",
       " 'they',\n",
       " 'want',\n",
       " 'to',\n",
       " 'die',\n",
       " '.',\n",
       " 'It',\n",
       " 'impacts',\n",
       " 'their',\n",
       " 'mental',\n",
       " 'psychological',\n",
       " 'social',\n",
       " 'and',\n",
       " 'physical',\n",
       " 'health',\n",
       " '.',\n",
       " 'Robots',\n",
       " 'prove',\n",
       " 'to',\n",
       " 'be',\n",
       " 'useless',\n",
       " 'in',\n",
       " 'these',\n",
       " 'matters',\n",
       " '.',\n",
       " 'They',\n",
       " 'can',\n",
       " 'provide',\n",
       " 'motivation',\n",
       " 'only',\n",
       " 'if',\n",
       " 'they',\n",
       " 'have',\n",
       " 'the',\n",
       " 'software',\n",
       " 'to',\n",
       " 'do',\n",
       " 'so',\n",
       " 'but',\n",
       " 'can',\n",
       " 't',\n",
       " 'themselves',\n",
       " 'react',\n",
       " 'to',\n",
       " 'such',\n",
       " 'a',\n",
       " 'situation',\n",
       " '.',\n",
       " 'They',\n",
       " 'don',\n",
       " 't',\n",
       " 'know',\n",
       " 'about',\n",
       " 'anger',\n",
       " 'happiness',\n",
       " 'or',\n",
       " 'sadness',\n",
       " '.',\n",
       " 'They',\n",
       " 'don',\n",
       " 't',\n",
       " 'themselves',\n",
       " 'bring',\n",
       " 'food',\n",
       " 'when',\n",
       " 'their',\n",
       " 'master',\n",
       " 'is',\n",
       " 'hungry',\n",
       " 'until',\n",
       " 'commanded',\n",
       " 'to',\n",
       " 'do',\n",
       " 'so',\n",
       " '.',\n",
       " 'They',\n",
       " 'can',\n",
       " 't',\n",
       " 'even',\n",
       " 'offer',\n",
       " 'a',\n",
       " 'glass',\n",
       " 'of',\n",
       " 'water',\n",
       " 'themselves',\n",
       " '.',\n",
       " 'A',\n",
       " 'man',\n",
       " 'living',\n",
       " 'without',\n",
       " 'relations',\n",
       " 'and',\n",
       " 'without',\n",
       " 'fellow',\n",
       " 'feeling',\n",
       " 'no',\n",
       " 'longer',\n",
       " 'remains',\n",
       " 'a',\n",
       " 'human',\n",
       " 'being',\n",
       " '.',\n",
       " 'He',\n",
       " 'becomes',\n",
       " 'none',\n",
       " 'less',\n",
       " 'than',\n",
       " 'a',\n",
       " 'machine',\n",
       " 'as',\n",
       " 'due',\n",
       " 'to',\n",
       " 'his',\n",
       " 'loneliness',\n",
       " 'he',\n",
       " 'becomes',\n",
       " 'mentally',\n",
       " 'ill',\n",
       " 'and',\n",
       " 'goes',\n",
       " 'into',\n",
       " 'a',\n",
       " 'condition',\n",
       " 'like',\n",
       " 'trauma',\n",
       " 'where',\n",
       " 'he',\n",
       " 'no',\n",
       " 'longer',\n",
       " 'enjoys',\n",
       " 'nature',\n",
       " 's',\n",
       " 'blessings',\n",
       " 'becomes',\n",
       " 'happy',\n",
       " 'or',\n",
       " 'sad',\n",
       " 'as',\n",
       " 'he',\n",
       " 'loses',\n",
       " 'the',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'react',\n",
       " 'and',\n",
       " 'hence',\n",
       " 'can',\n",
       " 't',\n",
       " 'act',\n",
       " '.',\n",
       " 'It',\n",
       " 's',\n",
       " 'a',\n",
       " 'dangerous',\n",
       " 'situation',\n",
       " '.',\n",
       " 'We',\n",
       " 'face',\n",
       " 'a',\n",
       " 'plethora',\n",
       " 'of',\n",
       " 'challenges',\n",
       " 'in',\n",
       " 'assisted',\n",
       " 'living',\n",
       " 'facilities',\n",
       " 'such',\n",
       " 'as',\n",
       " 'not',\n",
       " 'being',\n",
       " 'addressed',\n",
       " 'to',\n",
       " 'emotional',\n",
       " 'needs',\n",
       " 'being',\n",
       " 'neglected',\n",
       " 'and',\n",
       " 'forcing',\n",
       " 'a',\n",
       " 'withdrawal',\n",
       " 'from',\n",
       " 'social',\n",
       " 'activities',\n",
       " '.',\n",
       " 'Relations',\n",
       " 'in',\n",
       " 'life',\n",
       " 'interaction',\n",
       " 'with',\n",
       " 'fellow',\n",
       " 'beings',\n",
       " 'sharing',\n",
       " 'of',\n",
       " 'joy',\n",
       " 'and',\n",
       " 'happiness',\n",
       " 'and',\n",
       " 'fellow',\n",
       " 'feeling',\n",
       " 'make',\n",
       " 'a',\n",
       " 'man',\n",
       " 'from',\n",
       " 'mere',\n",
       " 'a',\n",
       " '‘',\n",
       " 'being',\n",
       " 'to',\n",
       " 'a',\n",
       " '‘',\n",
       " 'social',\n",
       " 'being',\n",
       " 'and',\n",
       " 'finally',\n",
       " 'a',\n",
       " 'human',\n",
       " 'being',\n",
       " '.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = word_tokenize(texts)\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10016a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"D:\\lab\\Dataset\\Stopwords_Blackcoffer.txt\", 'r') as file:\n",
    "    data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c567cbef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ERNST\\nYOUNG\\nDELOITTE\\nTOUCHE\\nKPMG\\nPRICEWATERHOUSECOOPERS\\nPRICEWATERHOUSE\\nCOOPERS\\nAFGHANI\\nARIARY\\nBAHT\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d65bfa92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ERNST,YOUNG,DELOITTE,TOUCHE,KPMG,PRICEWATERHOUSECOOPERS,PRICEWATERHOUSE,COOPERS,AFGHANI,ARIARY,BAHT,'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.replace('\\n', ',')\n",
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ef23874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In busy life . No spares . robots tackle life loneliness We stand stare . This loneliness . Loneliness due fast moving life hurry worry . In 21st century spending earning money . They day day transfor'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_texts = \" \".join([i for i in token if i not in data])\n",
    "new_texts[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea392da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length before cleaning:  4695\n",
      "length after cleaning:  2673\n"
     ]
    }
   ],
   "source": [
    "print(\"length before cleaning: \", len(texts))\n",
    "print(\"length after cleaning: \", len(new_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f456147",
   "metadata": {},
   "source": [
    "# Negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc3618a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"D:\\\\lab\\\\Dataset\\\\Negative_words.txt\", 'r') as file:\n",
    "    negative = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2123c4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2-faced\\n2-faces\\nabnormal\\nabolish\\nabominable\\nabominably\\nabominate\\nabomination\\nabort\\naborted\\naborts\\nabrade\\nabrasive\\nabrupt\\nabruptly\\nabscond\\nabsence\\nabsent-minded\\nabsentee\\nabsurd\\nabsurdity\\nabsurdly\\nabsurdness\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative[:206]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28f44c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2-faced,2-faces,abnormal,abolish,abominable,abominably,abominate,abomination,abort,aborted,aborts,abrade,abrasive,abrupt,abruptly,abscond,absence,absent-minded,absentee,absurd,absurdity,absurdly,absurdness,'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative = negative.replace('\\n', ',')\n",
    "negative[:206]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31a272c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['busy', 'life', 'life', 'loneliness', 'stand', 'loneliness', 'due', 'fast', 'moving', 'life', 'worry', 'day', 'day', 'losing', 'busy', 'satisfies', 'race', 'make', 'settled', 'order', 'faces', 'kind', 'age', 'spend', 'age', 'feel', 'lonely', 'understand', 'life', 'continue', 'easily', 'loneliness', 'social', 'isolation', 'older', 'order', 'serve', 'care', 'feeling', 'creative', 'work', 'human', 'loophole', 'life', 'loneliness', 'serve', 'incapable', 'understand', 'react', 'satisfaction', 'loneliness', 'due', 'service', 'lonely', 'life', 'feel', 'feel', 'react', 'advise', 'day', 'day', 'life', 'problems', 'fill', 'void', 'heart', 'person', 'struggling', 'life', 'loneliness', 'kind', 'mental', 'experience', 'fame', 'lonely', 'life', 'person', 'life', 'bond', 'care', 'react', 'loneliness', 'eats', 'crack', 'weep', 'understand', 'depression', 'symptoms', 'older', 'significant', 'quality', 'life', 'sick', 'loneliness', 'needed', 'die', 'mental', 'social', 'health', 'prove', 'useless', 'react', 'anger', 'happiness', 'sadness', 'water', 'feeling', 'human', 'due', 'loneliness', 'trauma', 'nature', 'happy', 'sad', 'loses', 'ability', 'react', 'dangerous', 'face', 'neglected', 'social', 'life', 'joy', 'happiness', 'feeling', 'make', 'social', 'human']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_texts = word_tokenize(new_texts)\n",
    "negative_words = [i for i in new_texts if i in negative]\n",
    "print(negative_words)\n",
    "len(negative_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b24f011",
   "metadata": {},
   "source": [
    "# Positive words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b003620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a+\\nabound\\nabounds\\nabundance\\nabundant\\naccessable\\naccessible\\nacclaim\\nacclaimed\\nacclamation\\naccolade\\naccolades\\naccommodative\\naccomodative\\naccomplish\\naccomplished\\naccomplishment\\naccomplishments\\naccurate\\naccurately\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"D:\\\\lab\\\\Dataset\\\\Positive_words.txt\", 'r') as file:\n",
    "    positive = file.read()\n",
    "positive[:210]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66ed38c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a+,abound,abounds,abundance,abundant,accessable,accessible,acclaim,acclaimed,acclamation,accolade,accolades,accommodative,accomodative,accomplish,accomplished,accomplishment,accomplishments,accurate,accurately,'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive = positive.replace('\\n',',')\n",
    "positive[:210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc1387e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['life', 'life', 'stand', 'fast', 'life', 'satisfies', 'race', 'order', 'kind', 'age', 'age', 'memorable', 'understand', 'life', 'order', 'serve', 'purpose', 'care', 'creative', 'work', 'human', 'life', 'serve', 'masters', 'masters', 'understand', 'satisfaction', 'gratification', 'master', 'life', 'listen', 'life', 'great', 'progress', 'fill', 'heart', 'person', 'life', 'kind', 'mental', 'trance', 'fame', 'progress', 'wealth', 'world', 'life', 'wealth', 'person', 'life', 'enjoy', 'care', 'eats', 'weep', 'establish', 'understand', 'prominent', 'condition', 'significant', 'quality', 'life', 'world', 'die', 'mental', 'health', 'prove', 'happiness', 'master', 'human', 'mentally', 'condition', 'enjoys', 'happy', 'ability', 'life', 'joy', 'happiness', 'human']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_words = [i for i in new_texts if i in positive]\n",
    "print(positive_words)\n",
    "len(positive_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b59646d",
   "metadata": {},
   "source": [
    "#### positive Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d0fbab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    }
   ],
   "source": [
    "pos_score = len(positive_words)\n",
    "print(pos_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a6cc12",
   "metadata": {},
   "source": [
    "#### Negative Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df0766cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "neg_score=len(negative_words)\n",
    "print(neg_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84da7ab7",
   "metadata": {},
   "source": [
    "#### Polarity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21e88c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.25"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Polarity_Score = (pos_score - neg_score)/((pos_score + neg_score) + 0.000001)\n",
    "round(Polarity_Score,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08bcb4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words after cleaning : 405\n"
     ]
    }
   ],
   "source": [
    "word_count = len(new_texts)\n",
    "print(\"number of words after cleaning :\",word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16495ba1",
   "metadata": {},
   "source": [
    "#### Subjectivity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "841713a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Subjectivity_Score = (pos_score + neg_score)/ ((word_count) + 0.000001)\n",
    "round(Subjectivity_Score,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7c370e",
   "metadata": {},
   "source": [
    "# Analysis of Readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10209a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "885"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "word_tokens = nltk.word_tokenize(texts)\n",
    "No_of_words = len(word_tokens)\n",
    "No_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bfac2ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokens = nltk.sent_tokenize(texts)\n",
    "No_of_sents = len(sent_tokens)\n",
    "No_of_sents "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1576acfe",
   "metadata": {},
   "source": [
    "### Average sentence Length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11d6a7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.39"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Avg_Sents_Length = No_of_words / No_of_sents\n",
    "round(Avg_Sents_Length,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc20ee3d",
   "metadata": {},
   "source": [
    "### Percentage of Complex words\n",
    "Complex words: words with more than 2 syllable are called complex words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eba6a8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of complex words: 94\n",
      "Total number of words: 4695\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import cmudict\n",
    "cmud = cmudict.dict()\n",
    "\n",
    "# Defining a function to count syllables in a word\n",
    "def count_syllables(word):\n",
    "    phonemes = cmud[word.lower()][0] \n",
    "    return len([s for s in phonemes if s[-1].isdigit()])\n",
    "\n",
    "# Identifing complex words\n",
    "w_tokens = [i for i in word_tokens if i in cmud]\n",
    "complex_words = [word for word in w_tokens if count_syllables(word) > 2]\n",
    "\n",
    "# Calculatingnumber of complex words\n",
    "num_complex_words = len(complex_words)\n",
    "\n",
    "print(\"Number of complex words:\", num_complex_words)\n",
    "print(\"Total number of words:\", len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e982c0a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.95"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Perc_of_Complex_words = len(texts) / num_complex_words\n",
    "round(Perc_of_Complex_words,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e948d1",
   "metadata": {},
   "source": [
    "### Fog Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95fb10bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sentence length: 54.0\n"
     ]
    }
   ],
   "source": [
    "# Tokenize each sentence into words\n",
    "words = [word_tokens for sentence in sent_tokens]\n",
    "\n",
    "# Calculate the average sentence length\n",
    "avg_sent_len = sum(No_of_sents for sentence in words) / No_of_sents\n",
    "\n",
    "print(\"Average sentence length:\", avg_sent_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38f5a93b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.58"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fog_index = 0.4 * (avg_sent_len + Perc_of_Complex_words)\n",
    "round(Fog_index,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4aacea",
   "metadata": {},
   "source": [
    "# Average Number of Words Per Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45da1407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.39"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_no_of_words_per_sent = No_of_words / No_of_sents\n",
    "round(avg_no_of_words_per_sent,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d9b493",
   "metadata": {},
   "source": [
    "# Complex Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "75304424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complex word count: 94\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import cmudict\n",
    "cmud = cmudict.dict()\n",
    "\n",
    "# Defining a function to count syllables in a word\n",
    "def count_syllables(word):\n",
    "    phonemes = cmud[word.lower()][0] \n",
    "    return len([s for s in phonemes if s[-1].isdigit()])\n",
    "\n",
    "# Identifing complex words\n",
    "w_tokens = [i for i in word_tokens if i in cmud]\n",
    "complex_words = [word for word in w_tokens if count_syllables(word) > 2]\n",
    "\n",
    "# Calculatingnumber of complex words\n",
    "num_complex_words = len(complex_words)\n",
    "\n",
    "print(\"complex word count:\", num_complex_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ea5188",
   "metadata": {},
   "source": [
    "# Word Count\n",
    "number of words after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4fb0c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8076ff",
   "metadata": {},
   "source": [
    "# Syllable Count Per Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f0b4e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a word to get syllable: relation\n",
      "Number of syllable in a word : 3\n"
     ]
    }
   ],
   "source": [
    "word = input(\"Enter a word to get syllable: \")\n",
    "def count_syllables(word):\n",
    "    phonemes = cmud[word.lower()][0] \n",
    "    return len([s for s in phonemes if s[-1].isdigit()])\n",
    "\n",
    "print(\"Number of syllable in a word :\",count_syllables(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3a18f6",
   "metadata": {},
   "source": [
    "# Personal Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b8e0d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Personal pronoun frequency: {'we': 15, 'they': 26, 'them': 4, 'us': 4, 'it': 5, 'him': 1, 'he': 4}\n",
      "total number of pronouns in a article : 59\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define a regex pattern to match personal pronouns\n",
    "pattern = r'\\b(I|you|he|she|it|we|they|me|him|her|us|them)\\b'\n",
    "\n",
    "# Count the frequency of personal pronouns\n",
    "pronoun_freq = {}\n",
    "for pronoun in re.findall(pattern, texts, re.IGNORECASE):\n",
    "    pronoun = pronoun.lower()\n",
    "    if pronoun in pronoun_freq:\n",
    "        pronoun_freq[pronoun] += 1\n",
    "    else:\n",
    "        pronoun_freq[pronoun] = 1\n",
    "\n",
    "print(\"Personal pronoun frequency:\", pronoun_freq)\n",
    "def returnSum(dict):\n",
    " \n",
    "    sum = 0\n",
    "    for i in pronoun_freq.values():\n",
    "        sum = sum + i\n",
    " \n",
    "    return sum\n",
    "print(\"total number of pronouns in a article :\",returnSum(pronoun_freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fc87f8",
   "metadata": {},
   "source": [
    "# Average Word Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5bde37d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word length: 4.32\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total number of characters in all words\n",
    "total_chars = sum(len(word) for word in word_tokens)\n",
    "\n",
    "avg_word_length = total_chars / No_of_words\n",
    "\n",
    "print(\"Average word length:\", round(avg_word_length,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dc25ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819012c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
