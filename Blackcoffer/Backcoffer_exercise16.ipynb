{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9312f26",
   "metadata": {},
   "source": [
    "# Data scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef4785ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac2f2459",
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.get(\"https://insights.blackcoffer.com/ai-tool-alexa-google-assistant-finance-banking-tool-future/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45f9fa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(req.content, \"html.parser\")\n",
    "res = soup.title\n",
    "paras = soup.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbb256b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Through AI tools like natural language processing, Alexa and google assistant has led the retail industry in its rise towards conversational commerce. As if a customer was interacting with a clerk in a retail store, conversational commerce makes it possible for users to engage with software to research, purchase, or get customer assistance with products and services across a wide range of industries. With Alexa, for example, users can ask any Alexa-enabled device to add an item to an Amazon shopping cart, set a purchasing reminder when a product is running low, or carry out a complete purchase without having to access a shopping cart. The result is a seamless conversational experience that enables consumers to carry out transactions as quickly as it takes to speak a sentence. Through AI tools like natural language processing, Alexa has led the retail industry in its rise towards conversational commerce. As if a customer was interacting with a clerk in a retail store, conversational commerce makes it possible for users to engage with software to research, purchase, or get customer assistance with products and services across a wide range of industries. With the advent of personalized products and on-call delivery, customers have come to expect a new standard experience: fast, easy, accurate, and personalized. Accomplishing this without sacrificing your workday can be a challenge, since the data processing required to meet these needs is immense. Luckily, virtual agents (VAs), powered by conversational AI, can utilize this information faster and more accurately than humans, finding insights and automating communication to deliver an enriched customer experience. If you invest based on these improvements, you’ll find that implementing these tools delivers a powerful competitive advantage. AI has helped in automobile, education, retail and commerce, finance and banking and healthcare. Voice AI has powered the wheels of conversational e-commerce, which has impacted the way the customer communicates with the brand in multiple industries. Brands generally build a campaign to emotionally connect with customers, for long-term growth. With Voice, brand campaigns need to be short and ones that can lead to immediate buying. Conversational e-commerce is still in its nascent stage and it is expected to grow manifold in the coming years. The future of shopping is going to Voice AI and marketers have to get on the bandwagon fast to increase their brand value and visibility. Targeting will have to be highly personalized for success. Despite its narrow focus, conversation AI is an extremely lucrative technology for enterprises, helping businesses more profitable. While an AI chatbot is the most popular form of conversational AI, there are still many other use cases across the enterprise. While an exclusively chat- or voice-based shopping experience for all scenarios may never completely replace the in-person experience, conversational commerce will continue to grow as an added method of convenient and efficient communication. As users continue to become more accustomed to engaging with chatbots and voice-driven interfaces, expect more innovations in the space as brands continue to develop their unique conversation-based solutions. \n"
     ]
    }
   ],
   "source": [
    "texts = \" \".join([paragraph.text.strip() for paragraph in paras])\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e79f5f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3273"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8f1fcc",
   "metadata": {},
   "source": [
    "Removing Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5285c8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3273"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "texts = re.sub(r'[\\'\\“\\”\\()\\%\\,\\-\\'\\’\\?\\ ]', ' ', texts)\n",
    "texts[0:200]\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fafe7be",
   "metadata": {},
   "source": [
    "# Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "089b8663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "280876b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Through',\n",
       " 'AI',\n",
       " 'tools',\n",
       " 'like',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'Alexa',\n",
       " 'and',\n",
       " 'google',\n",
       " 'assistant',\n",
       " 'has',\n",
       " 'led',\n",
       " 'the',\n",
       " 'retail',\n",
       " 'industry',\n",
       " 'in',\n",
       " 'its',\n",
       " 'rise',\n",
       " 'towards',\n",
       " 'conversational',\n",
       " 'commerce',\n",
       " '.',\n",
       " 'As',\n",
       " 'if',\n",
       " 'a',\n",
       " 'customer',\n",
       " 'was',\n",
       " 'interacting',\n",
       " 'with',\n",
       " 'a',\n",
       " 'clerk',\n",
       " 'in',\n",
       " 'a',\n",
       " 'retail',\n",
       " 'store',\n",
       " 'conversational',\n",
       " 'commerce',\n",
       " 'makes',\n",
       " 'it',\n",
       " 'possible',\n",
       " 'for',\n",
       " 'users',\n",
       " 'to',\n",
       " 'engage',\n",
       " 'with',\n",
       " 'software',\n",
       " 'to',\n",
       " 'research',\n",
       " 'purchase',\n",
       " 'or',\n",
       " 'get',\n",
       " 'customer',\n",
       " 'assistance',\n",
       " 'with',\n",
       " 'products',\n",
       " 'and',\n",
       " 'services',\n",
       " 'across',\n",
       " 'a',\n",
       " 'wide',\n",
       " 'range',\n",
       " 'of',\n",
       " 'industries',\n",
       " '.',\n",
       " 'With',\n",
       " 'Alexa',\n",
       " 'for',\n",
       " 'example',\n",
       " 'users',\n",
       " 'can',\n",
       " 'ask',\n",
       " 'any',\n",
       " 'Alexa',\n",
       " 'enabled',\n",
       " 'device',\n",
       " 'to',\n",
       " 'add',\n",
       " 'an',\n",
       " 'item',\n",
       " 'to',\n",
       " 'an',\n",
       " 'Amazon',\n",
       " 'shopping',\n",
       " 'cart',\n",
       " 'set',\n",
       " 'a',\n",
       " 'purchasing',\n",
       " 'reminder',\n",
       " 'when',\n",
       " 'a',\n",
       " 'product',\n",
       " 'is',\n",
       " 'running',\n",
       " 'low',\n",
       " 'or',\n",
       " 'carry',\n",
       " 'out',\n",
       " 'a',\n",
       " 'complete',\n",
       " 'purchase',\n",
       " 'without',\n",
       " 'having',\n",
       " 'to',\n",
       " 'access',\n",
       " 'a',\n",
       " 'shopping',\n",
       " 'cart',\n",
       " '.',\n",
       " 'The',\n",
       " 'result',\n",
       " 'is',\n",
       " 'a',\n",
       " 'seamless',\n",
       " 'conversational',\n",
       " 'experience',\n",
       " 'that',\n",
       " 'enables',\n",
       " 'consumers',\n",
       " 'to',\n",
       " 'carry',\n",
       " 'out',\n",
       " 'transactions',\n",
       " 'as',\n",
       " 'quickly',\n",
       " 'as',\n",
       " 'it',\n",
       " 'takes',\n",
       " 'to',\n",
       " 'speak',\n",
       " 'a',\n",
       " 'sentence',\n",
       " '.',\n",
       " 'Through',\n",
       " 'AI',\n",
       " 'tools',\n",
       " 'like',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'Alexa',\n",
       " 'has',\n",
       " 'led',\n",
       " 'the',\n",
       " 'retail',\n",
       " 'industry',\n",
       " 'in',\n",
       " 'its',\n",
       " 'rise',\n",
       " 'towards',\n",
       " 'conversational',\n",
       " 'commerce',\n",
       " '.',\n",
       " 'As',\n",
       " 'if',\n",
       " 'a',\n",
       " 'customer',\n",
       " 'was',\n",
       " 'interacting',\n",
       " 'with',\n",
       " 'a',\n",
       " 'clerk',\n",
       " 'in',\n",
       " 'a',\n",
       " 'retail',\n",
       " 'store',\n",
       " 'conversational',\n",
       " 'commerce',\n",
       " 'makes',\n",
       " 'it',\n",
       " 'possible',\n",
       " 'for',\n",
       " 'users',\n",
       " 'to',\n",
       " 'engage',\n",
       " 'with',\n",
       " 'software',\n",
       " 'to',\n",
       " 'research',\n",
       " 'purchase',\n",
       " 'or',\n",
       " 'get',\n",
       " 'customer',\n",
       " 'assistance',\n",
       " 'with',\n",
       " 'products',\n",
       " 'and',\n",
       " 'services',\n",
       " 'across',\n",
       " 'a',\n",
       " 'wide',\n",
       " 'range',\n",
       " 'of',\n",
       " 'industries',\n",
       " '.',\n",
       " 'With',\n",
       " 'the',\n",
       " 'advent',\n",
       " 'of',\n",
       " 'personalized',\n",
       " 'products',\n",
       " 'and',\n",
       " 'on',\n",
       " 'call',\n",
       " 'delivery',\n",
       " 'customers',\n",
       " 'have',\n",
       " 'come',\n",
       " 'to',\n",
       " 'expect',\n",
       " 'a',\n",
       " 'new',\n",
       " 'standard',\n",
       " 'experience',\n",
       " ':',\n",
       " 'fast',\n",
       " 'easy',\n",
       " 'accurate',\n",
       " 'and',\n",
       " 'personalized',\n",
       " '.',\n",
       " 'Accomplishing',\n",
       " 'this',\n",
       " 'without',\n",
       " 'sacrificing',\n",
       " 'your',\n",
       " 'workday',\n",
       " 'can',\n",
       " 'be',\n",
       " 'a',\n",
       " 'challenge',\n",
       " 'since',\n",
       " 'the',\n",
       " 'data',\n",
       " 'processing',\n",
       " 'required',\n",
       " 'to',\n",
       " 'meet',\n",
       " 'these',\n",
       " 'needs',\n",
       " 'is',\n",
       " 'immense',\n",
       " '.',\n",
       " 'Luckily',\n",
       " 'virtual',\n",
       " 'agents',\n",
       " 'VAs',\n",
       " 'powered',\n",
       " 'by',\n",
       " 'conversational',\n",
       " 'AI',\n",
       " 'can',\n",
       " 'utilize',\n",
       " 'this',\n",
       " 'information',\n",
       " 'faster',\n",
       " 'and',\n",
       " 'more',\n",
       " 'accurately',\n",
       " 'than',\n",
       " 'humans',\n",
       " 'finding',\n",
       " 'insights',\n",
       " 'and',\n",
       " 'automating',\n",
       " 'communication',\n",
       " 'to',\n",
       " 'deliver',\n",
       " 'an',\n",
       " 'enriched',\n",
       " 'customer',\n",
       " 'experience',\n",
       " '.',\n",
       " 'If',\n",
       " 'you',\n",
       " 'invest',\n",
       " 'based',\n",
       " 'on',\n",
       " 'these',\n",
       " 'improvements',\n",
       " 'you',\n",
       " 'll',\n",
       " 'find',\n",
       " 'that',\n",
       " 'implementing',\n",
       " 'these',\n",
       " 'tools',\n",
       " 'delivers',\n",
       " 'a',\n",
       " 'powerful',\n",
       " 'competitive',\n",
       " 'advantage',\n",
       " '.',\n",
       " 'AI',\n",
       " 'has',\n",
       " 'helped',\n",
       " 'in',\n",
       " 'automobile',\n",
       " 'education',\n",
       " 'retail',\n",
       " 'and',\n",
       " 'commerce',\n",
       " 'finance',\n",
       " 'and',\n",
       " 'banking',\n",
       " 'and',\n",
       " 'healthcare',\n",
       " '.',\n",
       " 'Voice',\n",
       " 'AI',\n",
       " 'has',\n",
       " 'powered',\n",
       " 'the',\n",
       " 'wheels',\n",
       " 'of',\n",
       " 'conversational',\n",
       " 'e',\n",
       " 'commerce',\n",
       " 'which',\n",
       " 'has',\n",
       " 'impacted',\n",
       " 'the',\n",
       " 'way',\n",
       " 'the',\n",
       " 'customer',\n",
       " 'communicates',\n",
       " 'with',\n",
       " 'the',\n",
       " 'brand',\n",
       " 'in',\n",
       " 'multiple',\n",
       " 'industries',\n",
       " '.',\n",
       " 'Brands',\n",
       " 'generally',\n",
       " 'build',\n",
       " 'a',\n",
       " 'campaign',\n",
       " 'to',\n",
       " 'emotionally',\n",
       " 'connect',\n",
       " 'with',\n",
       " 'customers',\n",
       " 'for',\n",
       " 'long',\n",
       " 'term',\n",
       " 'growth',\n",
       " '.',\n",
       " 'With',\n",
       " 'Voice',\n",
       " 'brand',\n",
       " 'campaigns',\n",
       " 'need',\n",
       " 'to',\n",
       " 'be',\n",
       " 'short',\n",
       " 'and',\n",
       " 'ones',\n",
       " 'that',\n",
       " 'can',\n",
       " 'lead',\n",
       " 'to',\n",
       " 'immediate',\n",
       " 'buying',\n",
       " '.',\n",
       " 'Conversational',\n",
       " 'e',\n",
       " 'commerce',\n",
       " 'is',\n",
       " 'still',\n",
       " 'in',\n",
       " 'its',\n",
       " 'nascent',\n",
       " 'stage',\n",
       " 'and',\n",
       " 'it',\n",
       " 'is',\n",
       " 'expected',\n",
       " 'to',\n",
       " 'grow',\n",
       " 'manifold',\n",
       " 'in',\n",
       " 'the',\n",
       " 'coming',\n",
       " 'years',\n",
       " '.',\n",
       " 'The',\n",
       " 'future',\n",
       " 'of',\n",
       " 'shopping',\n",
       " 'is',\n",
       " 'going',\n",
       " 'to',\n",
       " 'Voice',\n",
       " 'AI',\n",
       " 'and',\n",
       " 'marketers',\n",
       " 'have',\n",
       " 'to',\n",
       " 'get',\n",
       " 'on',\n",
       " 'the',\n",
       " 'bandwagon',\n",
       " 'fast',\n",
       " 'to',\n",
       " 'increase',\n",
       " 'their',\n",
       " 'brand',\n",
       " 'value',\n",
       " 'and',\n",
       " 'visibility',\n",
       " '.',\n",
       " 'Targeting',\n",
       " 'will',\n",
       " 'have',\n",
       " 'to',\n",
       " 'be',\n",
       " 'highly',\n",
       " 'personalized',\n",
       " 'for',\n",
       " 'success',\n",
       " '.',\n",
       " 'Despite',\n",
       " 'its',\n",
       " 'narrow',\n",
       " 'focus',\n",
       " 'conversation',\n",
       " 'AI',\n",
       " 'is',\n",
       " 'an',\n",
       " 'extremely',\n",
       " 'lucrative',\n",
       " 'technology',\n",
       " 'for',\n",
       " 'enterprises',\n",
       " 'helping',\n",
       " 'businesses',\n",
       " 'more',\n",
       " 'profitable',\n",
       " '.',\n",
       " 'While',\n",
       " 'an',\n",
       " 'AI',\n",
       " 'chatbot',\n",
       " 'is',\n",
       " 'the',\n",
       " 'most',\n",
       " 'popular',\n",
       " 'form',\n",
       " 'of',\n",
       " 'conversational',\n",
       " 'AI',\n",
       " 'there',\n",
       " 'are',\n",
       " 'still',\n",
       " 'many',\n",
       " 'other',\n",
       " 'use',\n",
       " 'cases',\n",
       " 'across',\n",
       " 'the',\n",
       " 'enterprise',\n",
       " '.',\n",
       " 'While',\n",
       " 'an',\n",
       " 'exclusively',\n",
       " 'chat',\n",
       " 'or',\n",
       " 'voice',\n",
       " 'based',\n",
       " 'shopping',\n",
       " 'experience',\n",
       " 'for',\n",
       " 'all',\n",
       " 'scenarios',\n",
       " 'may',\n",
       " 'never',\n",
       " 'completely',\n",
       " 'replace',\n",
       " 'the',\n",
       " 'in',\n",
       " 'person',\n",
       " 'experience',\n",
       " 'conversational',\n",
       " 'commerce',\n",
       " 'will',\n",
       " 'continue',\n",
       " 'to',\n",
       " 'grow',\n",
       " 'as',\n",
       " 'an',\n",
       " 'added',\n",
       " 'method',\n",
       " 'of',\n",
       " 'convenient',\n",
       " 'and',\n",
       " 'efficient',\n",
       " 'communication',\n",
       " '.',\n",
       " 'As',\n",
       " 'users',\n",
       " 'continue',\n",
       " 'to',\n",
       " 'become',\n",
       " 'more',\n",
       " 'accustomed',\n",
       " 'to',\n",
       " 'engaging',\n",
       " 'with',\n",
       " 'chatbots',\n",
       " 'and',\n",
       " 'voice',\n",
       " 'driven',\n",
       " 'interfaces',\n",
       " 'expect',\n",
       " 'more',\n",
       " 'innovations',\n",
       " 'in',\n",
       " 'the',\n",
       " 'space',\n",
       " 'as',\n",
       " 'brands',\n",
       " 'continue',\n",
       " 'to',\n",
       " 'develop',\n",
       " 'their',\n",
       " 'unique',\n",
       " 'conversation',\n",
       " 'based',\n",
       " 'solutions',\n",
       " '.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = word_tokenize(texts)\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10016a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"D:\\lab\\Dataset\\Stopwords_Blackcoffer.txt\", 'r') as file:\n",
    "    data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c567cbef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ERNST\\nYOUNG\\nDELOITTE\\nTOUCHE\\nKPMG\\nPRICEWATERHOUSECOOPERS\\nPRICEWATERHOUSE\\nCOOPERS\\nAFGHANI\\nARIARY\\nBAHT\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d65bfa92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ERNST,YOUNG,DELOITTE,TOUCHE,KPMG,PRICEWATERHOUSECOOPERS,PRICEWATERHOUSE,COOPERS,AFGHANI,ARIARY,BAHT,'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.replace('\\n', ',')\n",
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ef23874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Through tools natural language processing Alexa google assistant led retail industry rise conversational commerce . As customer interacting clerk retail store conversational commerce makes users engag'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_texts = \" \".join([i for i in token if i not in data])\n",
    "new_texts[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea392da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length before cleaning:  3273\n",
      "length after cleaning:  2310\n"
     ]
    }
   ],
   "source": [
    "print(\"length before cleaning: \", len(texts))\n",
    "print(\"length after cleaning: \", len(new_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f456147",
   "metadata": {},
   "source": [
    "# Negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc3618a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"D:\\\\lab\\\\Dataset\\\\Negative_words.txt\", 'r') as file:\n",
    "    negative = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2123c4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2-faced\\n2-faces\\nabnormal\\nabolish\\nabominable\\nabominably\\nabominate\\nabomination\\nabort\\naborted\\naborts\\nabrade\\nabrasive\\nabrupt\\nabruptly\\nabscond\\nabsence\\nabsent-minded\\nabsentee\\nabsurd\\nabsurdity\\nabsurdly\\nabsurdness\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative[:206]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28f44c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2-faced,2-faces,abnormal,abolish,abominable,abominably,abominate,abomination,abort,aborted,aborts,abrade,abrasive,abrupt,abruptly,abscond,absence,absent-minded,absentee,absurd,absurdity,absurdly,absurdness,'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative = negative.replace('\\n', ',')\n",
    "negative[:206]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31a272c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['natural', 'led', 'range', 'add', 'item', 'cart', 'set', 'product', 'complete', 'access', 'cart', 'experience', 'takes', 'speak', 'natural', 'led', 'range', 'call', 'expect', 'standard', 'experience', 'fast', 'easy', 'accurate', 'powered', 'accurately', 'experience', 'competitive', 'advantage', 'powered', 'term', 'short', 'lead', 'stage', 'expected', 'grow', 'fast', 'success', 'narrow', 'profitable', 'popular', 'chat', 'experience', 'person', 'experience', 'continue', 'grow', 'convenient', 'efficient', 'continue', 'accustomed', 'expect', 'continue', 'develop']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_texts = word_tokenize(new_texts)\n",
    "negative_words = [i for i in new_texts if i in negative]\n",
    "print(negative_words)\n",
    "len(negative_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b24f011",
   "metadata": {},
   "source": [
    "# Positive words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b003620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a+\\nabound\\nabounds\\nabundance\\nabundant\\naccessable\\naccessible\\nacclaim\\nacclaimed\\nacclamation\\naccolade\\naccolades\\naccommodative\\naccomodative\\naccomplish\\naccomplished\\naccomplishment\\naccomplishments\\naccurate\\naccurately\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"D:\\\\lab\\\\Dataset\\\\Positive_words.txt\", 'r') as file:\n",
    "    positive = file.read()\n",
    "positive[:210]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66ed38c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a+,abound,abounds,abundance,abundant,accessable,accessible,acclaim,acclaimed,acclamation,accolade,accolades,accommodative,accomodative,accomplish,accomplished,accomplishment,accomplishments,accurate,accurately,'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive = positive.replace('\\n',',')\n",
    "positive[:210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc1387e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['led', 'store', 'add', 'item', 'set', 'product', 'access', 'seamless', 'takes', 'led', 'store', 'advent', 'personalized', 'call', 'expect', 'fast', 'easy', 'accurate', 'personalized', 'immense', 'faster', 'accurately', 'improvements', 'powerful', 'competitive', 'advantage', 'helped', 'brand', 'connect', 'term', 'brand', 'lead', 'expected', 'grow', 'future', 'fast', 'brand', 'personalized', 'success', 'lucrative', 'helping', 'popular', 'replace', 'person', 'grow', 'convenient', 'efficient', 'engaging', 'expect']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_words = [i for i in new_texts if i in positive]\n",
    "print(positive_words)\n",
    "len(positive_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b59646d",
   "metadata": {},
   "source": [
    "#### positive Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d0fbab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "pos_score = len(positive_words)\n",
    "print(pos_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a6cc12",
   "metadata": {},
   "source": [
    "#### Negative Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df0766cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "neg_score=len(negative_words)\n",
    "print(neg_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84da7ab7",
   "metadata": {},
   "source": [
    "#### Polarity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21e88c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.05"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Polarity_Score = (pos_score - neg_score)/((pos_score + neg_score) + 0.000001)\n",
    "round(Polarity_Score,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08bcb4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words after cleaning : 292\n"
     ]
    }
   ],
   "source": [
    "word_count = len(new_texts)\n",
    "print(\"number of words after cleaning :\",word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16495ba1",
   "metadata": {},
   "source": [
    "#### Subjectivity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "841713a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Subjectivity_Score = (pos_score + neg_score)/ ((word_count) + 0.000001)\n",
    "round(Subjectivity_Score,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7c370e",
   "metadata": {},
   "source": [
    "# Analysis of Readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10209a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "531"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "word_tokens = nltk.word_tokenize(texts)\n",
    "No_of_words = len(word_tokens)\n",
    "No_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bfac2ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokens = nltk.sent_tokenize(texts)\n",
    "No_of_sents = len(sent_tokens)\n",
    "No_of_sents "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1576acfe",
   "metadata": {},
   "source": [
    "### Average sentence Length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11d6a7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.29"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Avg_Sents_Length = No_of_words / No_of_sents\n",
    "round(Avg_Sents_Length,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc20ee3d",
   "metadata": {},
   "source": [
    "### Percentage of Complex words\n",
    "Complex words: words with more than 2 syllable are called complex words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eba6a8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of complex words: 106\n",
      "Total number of words: 3273\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import cmudict\n",
    "cmud = cmudict.dict()\n",
    "\n",
    "# Defining a function to count syllables in a word\n",
    "def count_syllables(word):\n",
    "    phonemes = cmud[word.lower()][0] \n",
    "    return len([s for s in phonemes if s[-1].isdigit()])\n",
    "\n",
    "# Identifing complex words\n",
    "w_tokens = [i for i in word_tokens if i in cmud]\n",
    "complex_words = [word for word in w_tokens if count_syllables(word) > 2]\n",
    "\n",
    "# Calculatingnumber of complex words\n",
    "num_complex_words = len(complex_words)\n",
    "\n",
    "print(\"Number of complex words:\", num_complex_words)\n",
    "print(\"Total number of words:\", len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e982c0a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.88"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Perc_of_Complex_words = len(texts) / num_complex_words\n",
    "round(Perc_of_Complex_words,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e948d1",
   "metadata": {},
   "source": [
    "### Fog Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95fb10bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sentence length: 21.0\n"
     ]
    }
   ],
   "source": [
    "# Tokenize each sentence into words\n",
    "words = [word_tokens for sentence in sent_tokens]\n",
    "\n",
    "# Calculate the average sentence length\n",
    "avg_sent_len = sum(No_of_sents for sentence in words) / No_of_sents\n",
    "\n",
    "print(\"Average sentence length:\", avg_sent_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38f5a93b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.75"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fog_index = 0.4 * (avg_sent_len + Perc_of_Complex_words)\n",
    "round(Fog_index,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4aacea",
   "metadata": {},
   "source": [
    "# Average Number of Words Per Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45da1407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.29"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_no_of_words_per_sent = No_of_words / No_of_sents\n",
    "round(avg_no_of_words_per_sent,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d9b493",
   "metadata": {},
   "source": [
    "# Complex Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "75304424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complex word count: 106\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import cmudict\n",
    "cmud = cmudict.dict()\n",
    "\n",
    "# Defining a function to count syllables in a word\n",
    "def count_syllables(word):\n",
    "    phonemes = cmud[word.lower()][0] \n",
    "    return len([s for s in phonemes if s[-1].isdigit()])\n",
    "\n",
    "# Identifing complex words\n",
    "w_tokens = [i for i in word_tokens if i in cmud]\n",
    "complex_words = [word for word in w_tokens if count_syllables(word) > 2]\n",
    "\n",
    "# Calculatingnumber of complex words\n",
    "num_complex_words = len(complex_words)\n",
    "\n",
    "print(\"complex word count:\", num_complex_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ea5188",
   "metadata": {},
   "source": [
    "# Word Count\n",
    "number of words after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b4fb0c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "292"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8076ff",
   "metadata": {},
   "source": [
    "# Syllable Count Per Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc568045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a word to get syllable: industry\n",
      "Number of syllable in a word : 3\n"
     ]
    }
   ],
   "source": [
    "word = input(\"Enter a word to get syllable: \")\n",
    "def count_syllables(word):\n",
    "    phonemes = cmud[word.lower()][0] \n",
    "    return len([s for s in phonemes if s[-1].isdigit()])\n",
    "\n",
    "print(\"Number of syllable in a word :\",count_syllables(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3a18f6",
   "metadata": {},
   "source": [
    "# Personal Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b8e0d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Personal pronoun frequency: {'it': 4, 'you': 2}\n",
      "total number of pronouns in a article : 6\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define a regex pattern to match personal pronouns\n",
    "pattern = r'\\b(I|you|he|she|it|we|they|me|him|her|us|them)\\b'\n",
    "\n",
    "# Count the frequency of personal pronouns\n",
    "pronoun_freq = {}\n",
    "for pronoun in re.findall(pattern, texts, re.IGNORECASE):\n",
    "    pronoun = pronoun.lower()\n",
    "    if pronoun in pronoun_freq:\n",
    "        pronoun_freq[pronoun] += 1\n",
    "    else:\n",
    "        pronoun_freq[pronoun] = 1\n",
    "\n",
    "print(\"Personal pronoun frequency:\", pronoun_freq)\n",
    "def returnSum(dict):\n",
    " \n",
    "    sum = 0\n",
    "    for i in pronoun_freq.values():\n",
    "        sum = sum + i\n",
    " \n",
    "    return sum\n",
    "print(\"total number of pronouns in a article :\",returnSum(pronoun_freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fc87f8",
   "metadata": {},
   "source": [
    "# Average Word Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5bde37d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word length: 5.14\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total number of characters in all words\n",
    "total_chars = sum(len(word) for word in word_tokens)\n",
    "\n",
    "avg_word_length = total_chars / No_of_words\n",
    "\n",
    "print(\"Average word length:\", round(avg_word_length,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dc25ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819012c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
