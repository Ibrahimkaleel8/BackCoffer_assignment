{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9312f26",
   "metadata": {},
   "source": [
    "# Data scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef4785ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac2f2459",
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.get(\"https://insights.blackcoffer.com/how-machine-learning-will-affect-your-business/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45f9fa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(req.content, \"html.parser\")\n",
    "res = soup.title\n",
    "paras = soup.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbb256b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning techniques may have been used for years, but recently there has been an explosion in their applications. In fact, in a recent Q3 earnings call, Google CEO Sundar Pichai said “Machine learning is a core, transformative way by which we’re re-thinking how we’re doing everything.” And they’re far from the only business making that claim. In the past, successful use of machine learning algorithms required bespoke algorithms and huge R&D budgets, but all that is changing. IBM Watson, Microsoft Azure, Amazon, and Alibaba all launched turnkey cloud-based machine-learning SaaS solutions in 2015. At the same time startups like Idibon, MetaMind, Dato, and MonkeyLearn have built machine learning products that companies can take advantage of. Gartner already puts machine learning at the top of its hype curve, and no: machine learning won’t replace all of your employees with computers or suddenly double your revenue. But that doesn’t mean that it can’t give every business a competitive advantage. There are plenty of business processes that can significantly benefit from machine learning. So how does machine learning change the way businesses operate? First thing’s first: Machine learning needs training data and training data costs money. Especially training data labeled by humans. Let me explain. To make machine learning work for business, the algorithm needs to see lots and lots of examples of what it’s supposed to be doing. If you want an algorithm to tell you if a sales lead is good, you need to show it lots and lots of examples of good sales leads and bad sales leads. If you want an algorithm to tag the support tickets you need to show it many examples of support tickets. If you localize your algorithm to a new language you probably need to collect lots of examples in that language. In some instances, a company may have those training sets in-house. For example, a bunch of disqualified or qualified leads. But say you haven’t labeled each of your support tickets as they’ve come in over the year. You’d need to have people either in-house or en masse via a data enrichment platform -label those tickets. The machine will then look at those judgments and start finding connections and patterns it can learn from. Machine learning is much cheaper and more efficient than people when it works well. The downside is that it often works well in 80 percent of the cases and badly in 20 percent of the cases, and lowering the 20 percent error rate is hard, if not impossible. But even an 80 percent accurate algorithm can save you a lot of money because good machine learning algorithms know where they are accurate and where they are more likely to have errors. Smart companies take the cases where the algorithm has high confidence and uses those directly while sending low confidence cases to humans. Banks have been doing this for years. When you put a check in an ATM, an algorithm tries to decipher the numbers on the check. If you have really sloppy handwriting or the ink is smudged the algorithm passes the task to a human. This design pattern saves banks lots of money while preserving a very high level of accuracy. A huge benefit of machine learning is that it can turn part of your variable cost into more of a fixed cost. If you use humans to handle cases where that algorithm is struggling, you are creating the perfect training data to feed into your algorithm. This is a well-studied technique called active learning it turns out that training data labels collected on cases where the algorithm has low confidence help the algorithm learn much, much more efficiently. As the algorithm becomes increasingly more accurate, the unit economics of your business process become better and as machine learning becomes able to handle more cases, the expensive humans are only called in on the toughest, rarest situations. That means you use the best of both human and machine intelligence in tandem: leveraging the speed and reliability of computers for the easy judgments and the fluency and expertise of humans for the difficult ones. And if that sounds like smart business, it’s because it is.\n"
     ]
    }
   ],
   "source": [
    "texts = \" \".join([paragraph.text.strip() for paragraph in paras])\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e79f5f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4138"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8f1fcc",
   "metadata": {},
   "source": [
    "Removing Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5285c8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4138"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "texts = re.sub(r'[\\'\\“\\”\\()\\%\\,\\-\\'\\’\\?\\ ]', ' ', texts)\n",
    "texts[0:200]\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fafe7be",
   "metadata": {},
   "source": [
    "# Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "089b8663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "280876b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Machine',\n",
       " 'learning',\n",
       " 'techniques',\n",
       " 'may',\n",
       " 'have',\n",
       " 'been',\n",
       " 'used',\n",
       " 'for',\n",
       " 'years',\n",
       " 'but',\n",
       " 'recently',\n",
       " 'there',\n",
       " 'has',\n",
       " 'been',\n",
       " 'an',\n",
       " 'explosion',\n",
       " 'in',\n",
       " 'their',\n",
       " 'applications',\n",
       " '.',\n",
       " 'In',\n",
       " 'fact',\n",
       " 'in',\n",
       " 'a',\n",
       " 'recent',\n",
       " 'Q3',\n",
       " 'earnings',\n",
       " 'call',\n",
       " 'Google',\n",
       " 'CEO',\n",
       " 'Sundar',\n",
       " 'Pichai',\n",
       " 'said',\n",
       " 'Machine',\n",
       " 'learning',\n",
       " 'is',\n",
       " 'a',\n",
       " 'core',\n",
       " 'transformative',\n",
       " 'way',\n",
       " 'by',\n",
       " 'which',\n",
       " 'we',\n",
       " 're',\n",
       " 're',\n",
       " 'thinking',\n",
       " 'how',\n",
       " 'we',\n",
       " 're',\n",
       " 'doing',\n",
       " 'everything',\n",
       " '.',\n",
       " 'And',\n",
       " 'they',\n",
       " 're',\n",
       " 'far',\n",
       " 'from',\n",
       " 'the',\n",
       " 'only',\n",
       " 'business',\n",
       " 'making',\n",
       " 'that',\n",
       " 'claim',\n",
       " '.',\n",
       " 'In',\n",
       " 'the',\n",
       " 'past',\n",
       " 'successful',\n",
       " 'use',\n",
       " 'of',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'algorithms',\n",
       " 'required',\n",
       " 'bespoke',\n",
       " 'algorithms',\n",
       " 'and',\n",
       " 'huge',\n",
       " 'R',\n",
       " '&',\n",
       " 'D',\n",
       " 'budgets',\n",
       " 'but',\n",
       " 'all',\n",
       " 'that',\n",
       " 'is',\n",
       " 'changing',\n",
       " '.',\n",
       " 'IBM',\n",
       " 'Watson',\n",
       " 'Microsoft',\n",
       " 'Azure',\n",
       " 'Amazon',\n",
       " 'and',\n",
       " 'Alibaba',\n",
       " 'all',\n",
       " 'launched',\n",
       " 'turnkey',\n",
       " 'cloud',\n",
       " 'based',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'SaaS',\n",
       " 'solutions',\n",
       " 'in',\n",
       " '2015',\n",
       " '.',\n",
       " 'At',\n",
       " 'the',\n",
       " 'same',\n",
       " 'time',\n",
       " 'startups',\n",
       " 'like',\n",
       " 'Idibon',\n",
       " 'MetaMind',\n",
       " 'Dato',\n",
       " 'and',\n",
       " 'MonkeyLearn',\n",
       " 'have',\n",
       " 'built',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'products',\n",
       " 'that',\n",
       " 'companies',\n",
       " 'can',\n",
       " 'take',\n",
       " 'advantage',\n",
       " 'of',\n",
       " '.',\n",
       " 'Gartner',\n",
       " 'already',\n",
       " 'puts',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'at',\n",
       " 'the',\n",
       " 'top',\n",
       " 'of',\n",
       " 'its',\n",
       " 'hype',\n",
       " 'curve',\n",
       " 'and',\n",
       " 'no',\n",
       " ':',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'won',\n",
       " 't',\n",
       " 'replace',\n",
       " 'all',\n",
       " 'of',\n",
       " 'your',\n",
       " 'employees',\n",
       " 'with',\n",
       " 'computers',\n",
       " 'or',\n",
       " 'suddenly',\n",
       " 'double',\n",
       " 'your',\n",
       " 'revenue',\n",
       " '.',\n",
       " 'But',\n",
       " 'that',\n",
       " 'doesn',\n",
       " 't',\n",
       " 'mean',\n",
       " 'that',\n",
       " 'it',\n",
       " 'can',\n",
       " 't',\n",
       " 'give',\n",
       " 'every',\n",
       " 'business',\n",
       " 'a',\n",
       " 'competitive',\n",
       " 'advantage',\n",
       " '.',\n",
       " 'There',\n",
       " 'are',\n",
       " 'plenty',\n",
       " 'of',\n",
       " 'business',\n",
       " 'processes',\n",
       " 'that',\n",
       " 'can',\n",
       " 'significantly',\n",
       " 'benefit',\n",
       " 'from',\n",
       " 'machine',\n",
       " 'learning',\n",
       " '.',\n",
       " 'So',\n",
       " 'how',\n",
       " 'does',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'change',\n",
       " 'the',\n",
       " 'way',\n",
       " 'businesses',\n",
       " 'operate',\n",
       " 'First',\n",
       " 'thing',\n",
       " 's',\n",
       " 'first',\n",
       " ':',\n",
       " 'Machine',\n",
       " 'learning',\n",
       " 'needs',\n",
       " 'training',\n",
       " 'data',\n",
       " 'and',\n",
       " 'training',\n",
       " 'data',\n",
       " 'costs',\n",
       " 'money',\n",
       " '.',\n",
       " 'Especially',\n",
       " 'training',\n",
       " 'data',\n",
       " 'labeled',\n",
       " 'by',\n",
       " 'humans',\n",
       " '.',\n",
       " 'Let',\n",
       " 'me',\n",
       " 'explain',\n",
       " '.',\n",
       " 'To',\n",
       " 'make',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'work',\n",
       " 'for',\n",
       " 'business',\n",
       " 'the',\n",
       " 'algorithm',\n",
       " 'needs',\n",
       " 'to',\n",
       " 'see',\n",
       " 'lots',\n",
       " 'and',\n",
       " 'lots',\n",
       " 'of',\n",
       " 'examples',\n",
       " 'of',\n",
       " 'what',\n",
       " 'it',\n",
       " 's',\n",
       " 'supposed',\n",
       " 'to',\n",
       " 'be',\n",
       " 'doing',\n",
       " '.',\n",
       " 'If',\n",
       " 'you',\n",
       " 'want',\n",
       " 'an',\n",
       " 'algorithm',\n",
       " 'to',\n",
       " 'tell',\n",
       " 'you',\n",
       " 'if',\n",
       " 'a',\n",
       " 'sales',\n",
       " 'lead',\n",
       " 'is',\n",
       " 'good',\n",
       " 'you',\n",
       " 'need',\n",
       " 'to',\n",
       " 'show',\n",
       " 'it',\n",
       " 'lots',\n",
       " 'and',\n",
       " 'lots',\n",
       " 'of',\n",
       " 'examples',\n",
       " 'of',\n",
       " 'good',\n",
       " 'sales',\n",
       " 'leads',\n",
       " 'and',\n",
       " 'bad',\n",
       " 'sales',\n",
       " 'leads',\n",
       " '.',\n",
       " 'If',\n",
       " 'you',\n",
       " 'want',\n",
       " 'an',\n",
       " 'algorithm',\n",
       " 'to',\n",
       " 'tag',\n",
       " 'the',\n",
       " 'support',\n",
       " 'tickets',\n",
       " 'you',\n",
       " 'need',\n",
       " 'to',\n",
       " 'show',\n",
       " 'it',\n",
       " 'many',\n",
       " 'examples',\n",
       " 'of',\n",
       " 'support',\n",
       " 'tickets',\n",
       " '.',\n",
       " 'If',\n",
       " 'you',\n",
       " 'localize',\n",
       " 'your',\n",
       " 'algorithm',\n",
       " 'to',\n",
       " 'a',\n",
       " 'new',\n",
       " 'language',\n",
       " 'you',\n",
       " 'probably',\n",
       " 'need',\n",
       " 'to',\n",
       " 'collect',\n",
       " 'lots',\n",
       " 'of',\n",
       " 'examples',\n",
       " 'in',\n",
       " 'that',\n",
       " 'language',\n",
       " '.',\n",
       " 'In',\n",
       " 'some',\n",
       " 'instances',\n",
       " 'a',\n",
       " 'company',\n",
       " 'may',\n",
       " 'have',\n",
       " 'those',\n",
       " 'training',\n",
       " 'sets',\n",
       " 'in',\n",
       " 'house',\n",
       " '.',\n",
       " 'For',\n",
       " 'example',\n",
       " 'a',\n",
       " 'bunch',\n",
       " 'of',\n",
       " 'disqualified',\n",
       " 'or',\n",
       " 'qualified',\n",
       " 'leads',\n",
       " '.',\n",
       " 'But',\n",
       " 'say',\n",
       " 'you',\n",
       " 'haven',\n",
       " 't',\n",
       " 'labeled',\n",
       " 'each',\n",
       " 'of',\n",
       " 'your',\n",
       " 'support',\n",
       " 'tickets',\n",
       " 'as',\n",
       " 'they',\n",
       " 've',\n",
       " 'come',\n",
       " 'in',\n",
       " 'over',\n",
       " 'the',\n",
       " 'year',\n",
       " '.',\n",
       " 'You',\n",
       " 'd',\n",
       " 'need',\n",
       " 'to',\n",
       " 'have',\n",
       " 'people',\n",
       " 'either',\n",
       " 'in',\n",
       " 'house',\n",
       " 'or',\n",
       " 'en',\n",
       " 'masse',\n",
       " 'via',\n",
       " 'a',\n",
       " 'data',\n",
       " 'enrichment',\n",
       " 'platform',\n",
       " 'label',\n",
       " 'those',\n",
       " 'tickets',\n",
       " '.',\n",
       " 'The',\n",
       " 'machine',\n",
       " 'will',\n",
       " 'then',\n",
       " 'look',\n",
       " 'at',\n",
       " 'those',\n",
       " 'judgments',\n",
       " 'and',\n",
       " 'start',\n",
       " 'finding',\n",
       " 'connections',\n",
       " 'and',\n",
       " 'patterns',\n",
       " 'it',\n",
       " 'can',\n",
       " 'learn',\n",
       " 'from',\n",
       " '.',\n",
       " 'Machine',\n",
       " 'learning',\n",
       " 'is',\n",
       " 'much',\n",
       " 'cheaper',\n",
       " 'and',\n",
       " 'more',\n",
       " 'efficient',\n",
       " 'than',\n",
       " 'people',\n",
       " 'when',\n",
       " 'it',\n",
       " 'works',\n",
       " 'well',\n",
       " '.',\n",
       " 'The',\n",
       " 'downside',\n",
       " 'is',\n",
       " 'that',\n",
       " 'it',\n",
       " 'often',\n",
       " 'works',\n",
       " 'well',\n",
       " 'in',\n",
       " '80',\n",
       " 'percent',\n",
       " 'of',\n",
       " 'the',\n",
       " 'cases',\n",
       " 'and',\n",
       " 'badly',\n",
       " 'in',\n",
       " '20',\n",
       " 'percent',\n",
       " 'of',\n",
       " 'the',\n",
       " 'cases',\n",
       " 'and',\n",
       " 'lowering',\n",
       " 'the',\n",
       " '20',\n",
       " 'percent',\n",
       " 'error',\n",
       " 'rate',\n",
       " 'is',\n",
       " 'hard',\n",
       " 'if',\n",
       " 'not',\n",
       " 'impossible',\n",
       " '.',\n",
       " 'But',\n",
       " 'even',\n",
       " 'an',\n",
       " '80',\n",
       " 'percent',\n",
       " 'accurate',\n",
       " 'algorithm',\n",
       " 'can',\n",
       " 'save',\n",
       " 'you',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'money',\n",
       " 'because',\n",
       " 'good',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'algorithms',\n",
       " 'know',\n",
       " 'where',\n",
       " 'they',\n",
       " 'are',\n",
       " 'accurate',\n",
       " 'and',\n",
       " 'where',\n",
       " 'they',\n",
       " 'are',\n",
       " 'more',\n",
       " 'likely',\n",
       " 'to',\n",
       " 'have',\n",
       " 'errors',\n",
       " '.',\n",
       " 'Smart',\n",
       " 'companies',\n",
       " 'take',\n",
       " 'the',\n",
       " 'cases',\n",
       " 'where',\n",
       " 'the',\n",
       " 'algorithm',\n",
       " 'has',\n",
       " 'high',\n",
       " 'confidence',\n",
       " 'and',\n",
       " 'uses',\n",
       " 'those',\n",
       " 'directly',\n",
       " 'while',\n",
       " 'sending',\n",
       " 'low',\n",
       " 'confidence',\n",
       " 'cases',\n",
       " 'to',\n",
       " 'humans',\n",
       " '.',\n",
       " 'Banks',\n",
       " 'have',\n",
       " 'been',\n",
       " 'doing',\n",
       " 'this',\n",
       " 'for',\n",
       " 'years',\n",
       " '.',\n",
       " 'When',\n",
       " 'you',\n",
       " 'put',\n",
       " 'a',\n",
       " 'check',\n",
       " 'in',\n",
       " 'an',\n",
       " 'ATM',\n",
       " 'an',\n",
       " 'algorithm',\n",
       " 'tries',\n",
       " 'to',\n",
       " 'decipher',\n",
       " 'the',\n",
       " 'numbers',\n",
       " 'on',\n",
       " 'the',\n",
       " 'check',\n",
       " '.',\n",
       " 'If',\n",
       " 'you',\n",
       " 'have',\n",
       " 'really',\n",
       " 'sloppy',\n",
       " 'handwriting',\n",
       " 'or',\n",
       " 'the',\n",
       " 'ink',\n",
       " 'is',\n",
       " 'smudged',\n",
       " 'the',\n",
       " 'algorithm',\n",
       " 'passes',\n",
       " 'the',\n",
       " 'task',\n",
       " 'to',\n",
       " 'a',\n",
       " 'human',\n",
       " '.',\n",
       " 'This',\n",
       " 'design',\n",
       " 'pattern',\n",
       " 'saves',\n",
       " 'banks',\n",
       " 'lots',\n",
       " 'of',\n",
       " 'money',\n",
       " 'while',\n",
       " 'preserving',\n",
       " 'a',\n",
       " 'very',\n",
       " 'high',\n",
       " 'level',\n",
       " 'of',\n",
       " 'accuracy',\n",
       " '.',\n",
       " 'A',\n",
       " 'huge',\n",
       " 'benefit',\n",
       " 'of',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'is',\n",
       " 'that',\n",
       " 'it',\n",
       " 'can',\n",
       " 'turn',\n",
       " 'part',\n",
       " 'of',\n",
       " 'your',\n",
       " 'variable',\n",
       " 'cost',\n",
       " 'into',\n",
       " 'more',\n",
       " 'of',\n",
       " 'a',\n",
       " 'fixed',\n",
       " 'cost',\n",
       " '.',\n",
       " 'If',\n",
       " 'you',\n",
       " 'use',\n",
       " 'humans',\n",
       " 'to',\n",
       " 'handle',\n",
       " 'cases',\n",
       " 'where',\n",
       " 'that',\n",
       " 'algorithm',\n",
       " 'is',\n",
       " 'struggling',\n",
       " 'you',\n",
       " 'are',\n",
       " 'creating',\n",
       " 'the',\n",
       " 'perfect',\n",
       " 'training',\n",
       " 'data',\n",
       " 'to',\n",
       " 'feed',\n",
       " 'into',\n",
       " 'your',\n",
       " 'algorithm',\n",
       " '.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'a',\n",
       " 'well',\n",
       " 'studied',\n",
       " 'technique',\n",
       " 'called',\n",
       " 'active',\n",
       " 'learning',\n",
       " 'it',\n",
       " 'turns',\n",
       " 'out',\n",
       " 'that',\n",
       " 'training',\n",
       " 'data',\n",
       " 'labels',\n",
       " 'collected',\n",
       " 'on',\n",
       " 'cases',\n",
       " 'where',\n",
       " 'the',\n",
       " 'algorithm',\n",
       " 'has',\n",
       " 'low',\n",
       " 'confidence',\n",
       " 'help',\n",
       " 'the',\n",
       " 'algorithm',\n",
       " 'learn',\n",
       " 'much',\n",
       " 'much',\n",
       " 'more',\n",
       " 'efficiently',\n",
       " '.',\n",
       " 'As',\n",
       " 'the',\n",
       " 'algorithm',\n",
       " 'becomes',\n",
       " 'increasingly',\n",
       " 'more',\n",
       " 'accurate',\n",
       " 'the',\n",
       " 'unit',\n",
       " 'economics',\n",
       " 'of',\n",
       " 'your',\n",
       " 'business',\n",
       " 'process',\n",
       " 'become',\n",
       " 'better',\n",
       " 'and',\n",
       " 'as',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'becomes',\n",
       " 'able',\n",
       " 'to',\n",
       " 'handle',\n",
       " 'more',\n",
       " 'cases',\n",
       " 'the',\n",
       " 'expensive',\n",
       " 'humans',\n",
       " 'are',\n",
       " 'only',\n",
       " 'called',\n",
       " 'in',\n",
       " 'on',\n",
       " 'the',\n",
       " 'toughest',\n",
       " 'rarest',\n",
       " 'situations',\n",
       " '.',\n",
       " 'That',\n",
       " 'means',\n",
       " 'you',\n",
       " 'use',\n",
       " 'the',\n",
       " 'best',\n",
       " 'of',\n",
       " 'both',\n",
       " 'human',\n",
       " 'and',\n",
       " 'machine',\n",
       " 'intelligence',\n",
       " 'in',\n",
       " 'tandem',\n",
       " ':',\n",
       " 'leveraging',\n",
       " 'the',\n",
       " 'speed',\n",
       " 'and',\n",
       " 'reliability',\n",
       " 'of',\n",
       " 'computers',\n",
       " 'for',\n",
       " 'the',\n",
       " 'easy',\n",
       " 'judgments',\n",
       " 'and',\n",
       " 'the',\n",
       " 'fluency',\n",
       " 'and',\n",
       " 'expertise',\n",
       " 'of',\n",
       " 'humans',\n",
       " 'for',\n",
       " 'the',\n",
       " 'difficult',\n",
       " 'ones',\n",
       " '.',\n",
       " 'And',\n",
       " 'if',\n",
       " 'that',\n",
       " 'sounds',\n",
       " 'like',\n",
       " 'smart',\n",
       " 'business',\n",
       " 'it',\n",
       " 's',\n",
       " 'because',\n",
       " 'it',\n",
       " 'is',\n",
       " '.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = word_tokenize(texts)\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10016a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"D:\\lab\\Dataset\\Stopwords_Blackcoffer.txt\", 'r') as file:\n",
    "    data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c567cbef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ERNST\\nYOUNG\\nDELOITTE\\nTOUCHE\\nKPMG\\nPRICEWATERHOUSECOOPERS\\nPRICEWATERHOUSE\\nCOOPERS\\nAFGHANI\\nARIARY\\nBAHT\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d65bfa92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ERNST,YOUNG,DELOITTE,TOUCHE,KPMG,PRICEWATERHOUSECOOPERS,PRICEWATERHOUSE,COOPERS,AFGHANI,ARIARY,BAHT,'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.replace('\\n', ',')\n",
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ef23874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine learning techniques years recently explosion applications . In fact recent Q3 earnings call Google CEO Sundar Pichai Machine learning core transformative thinking . And business making claim .'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_texts = \" \".join([i for i in token if i not in data])\n",
    "new_texts[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea392da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length before cleaning:  4138\n",
      "length after cleaning:  2602\n"
     ]
    }
   ],
   "source": [
    "print(\"length before cleaning: \", len(texts))\n",
    "print(\"length after cleaning: \", len(new_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f456147",
   "metadata": {},
   "source": [
    "# Negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc3618a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"D:\\\\lab\\\\Dataset\\\\Negative_words.txt\", 'r') as file:\n",
    "    negative = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2123c4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2-faced\\n2-faces\\nabnormal\\nabolish\\nabominable\\nabominably\\nabominate\\nabomination\\nabort\\naborted\\naborts\\nabrade\\nabrasive\\nabrupt\\nabruptly\\nabscond\\nabsence\\nabsent-minded\\nabsentee\\nabsurd\\nabsurdity\\nabsurdly\\nabsurdness\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative[:206]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28f44c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2-faced,2-faces,abnormal,abolish,abominable,abominably,abominate,abomination,abort,aborted,aborts,abrade,abrasive,abrupt,abruptly,abscond,absence,absent-minded,absentee,absurd,absurdity,absurdly,absurdness,'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative = negative.replace('\\n', ',')\n",
    "negative[:206]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31a272c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fact', 'call', 'claim', 'successful', 'cloud', 'advantage', 'top', 'hype', 'competitive', 'advantage', 'significantly', 'training', 'training', 'training', 'explain', 'make', 'work', 'lead', 'show', 'bad', 'tag', 'support', 'show', 'support', 'collect', 'training', 'sets', 'house', 'qualified', 'support', 'house', 'start', 'efficient', 'downside', 'badly', 'error', 'rate', 'impossible', 'accurate', 'lot', 'accurate', 'errors', 'high', 'confidence', 'confidence', 'put', 'check', 'check', 'sloppy', 'smudged', 'human', 'design', 'high', 'accuracy', 'turn', 'cost', 'cost', 'handle', 'struggling', 'perfect', 'training', 'feed', 'active', 'turns', 'training', 'confidence', 'efficiently', 'accurate', 'unit', 'handle', 'expensive', 'human', 'reliability', 'easy', 'difficult']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_texts = word_tokenize(new_texts)\n",
    "negative_words = [i for i in new_texts if i in negative]\n",
    "print(negative_words)\n",
    "len(negative_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b24f011",
   "metadata": {},
   "source": [
    "# Positive words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b003620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a+\\nabound\\nabounds\\nabundance\\nabundant\\naccessable\\naccessible\\nacclaim\\nacclaimed\\nacclamation\\naccolade\\naccolades\\naccommodative\\naccomodative\\naccomplish\\naccomplished\\naccomplishment\\naccomplishments\\naccurate\\naccurately\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"D:\\\\lab\\\\Dataset\\\\Positive_words.txt\", 'r') as file:\n",
    "    positive = file.read()\n",
    "positive[:210]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66ed38c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a+,abound,abounds,abundance,abundant,accessable,accessible,acclaim,acclaimed,acclamation,accolade,accolades,accommodative,accomodative,accomplish,accomplished,accomplishment,accomplishments,accurate,accurately,'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive = positive.replace('\\n',',')\n",
    "positive[:210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc1387e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fact', 'call', 'claim', 'successful', 'advantage', 'top', 'replace', 'competitive', 'advantage', 'benefit', 'work', 'lead', 'good', 'good', 'leads', 'leads', 'tag', 'support', 'support', 'qualified', 'leads', 'support', 'enrichment', 'cheaper', 'efficient', 'works', 'works', 'rate', 'accurate', 'save', 'good', 'accurate', 'high', 'confidence', 'confidence', 'put', 'human', 'high', 'benefit', 'cost', 'cost', 'perfect', 'active', 'confidence', 'efficiently', 'accurate', 'unit', 'expensive', 'toughest', 'human', 'intelligence', 'speed', 'easy', 'smart']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_words = [i for i in new_texts if i in positive]\n",
    "print(positive_words)\n",
    "len(positive_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b59646d",
   "metadata": {},
   "source": [
    "#### positive Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d0fbab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "pos_score = len(positive_words)\n",
    "print(pos_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a6cc12",
   "metadata": {},
   "source": [
    "#### Negative Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df0766cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    }
   ],
   "source": [
    "neg_score=len(negative_words)\n",
    "print(neg_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84da7ab7",
   "metadata": {},
   "source": [
    "#### Polarity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21e88c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.16"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Polarity_Score = (pos_score - neg_score)/((pos_score + neg_score) + 0.000001)\n",
    "round(Polarity_Score,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08bcb4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words after cleaning : 380\n"
     ]
    }
   ],
   "source": [
    "print(\"number of words after cleaning :\",len(new_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16495ba1",
   "metadata": {},
   "source": [
    "#### Subjectivity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "841713a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Subjectivity_Score = (pos_score + neg_score)/ ((380) + 0.000001)\n",
    "round(Subjectivity_Score,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7c370e",
   "metadata": {},
   "source": [
    "# Analysis of Readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10209a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "756"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "word_tokens = nltk.word_tokenize(texts)\n",
    "No_of_words = len(word_tokens)\n",
    "No_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bfac2ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokens = nltk.sent_tokenize(texts)\n",
    "No_of_sents = len(sent_tokens)\n",
    "No_of_sents "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1576acfe",
   "metadata": {},
   "source": [
    "### Average sentence Length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11d6a7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.6"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Avg_Sents_Length = No_of_words / No_of_sents\n",
    "round(Avg_Sents_Length,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc20ee3d",
   "metadata": {},
   "source": [
    "### Percentage of Complex words\n",
    "Complex words: words with more than 2 syllable are called complex words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eba6a8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of complex words: 83\n",
      "Total number of words: 4138\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import cmudict\n",
    "cmud = cmudict.dict()\n",
    "\n",
    "# Defining a function to count syllables in a word\n",
    "def count_syllables(word):\n",
    "    phonemes = cmud[word.lower()][0] \n",
    "    return len([s for s in phonemes if s[-1].isdigit()])\n",
    "\n",
    "# Identifing complex words\n",
    "w_tokens = [i for i in word_tokens if i in cmud]\n",
    "complex_words = [word for word in w_tokens if count_syllables(word) > 2]\n",
    "\n",
    "# Calculatingnumber of complex words\n",
    "num_complex_words = len(complex_words)\n",
    "\n",
    "print(\"Number of complex words:\", num_complex_words)\n",
    "print(\"Total number of words:\", len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e982c0a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.86"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Perc_of_Complex_words = len(texts) / num_complex_words\n",
    "round(Perc_of_Complex_words,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e948d1",
   "metadata": {},
   "source": [
    "### Fog Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95fb10bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sentence length: 35.0\n"
     ]
    }
   ],
   "source": [
    "# Tokenize each sentence into words\n",
    "words = [word_tokens for sentence in sent_tokens]\n",
    "\n",
    "# Calculate the average sentence length\n",
    "avg_sent_len = sum(No_of_sents for sentence in words) / No_of_sents\n",
    "\n",
    "print(\"Average sentence length:\", avg_sent_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38f5a93b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.94"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fog_index = 0.4 * (avg_sent_len + Perc_of_Complex_words)\n",
    "round(Fog_index,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4aacea",
   "metadata": {},
   "source": [
    "# Average Number of Words Per Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45da1407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.6"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_no_of_words_per_sent = No_of_words / No_of_sents\n",
    "round(avg_no_of_words_per_sent,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d9b493",
   "metadata": {},
   "source": [
    "# Complex Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "75304424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complex word count: 83\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import cmudict\n",
    "cmud = cmudict.dict()\n",
    "\n",
    "# Defining a function to count syllables in a word\n",
    "def count_syllables(word):\n",
    "    phonemes = cmud[word.lower()][0] \n",
    "    return len([s for s in phonemes if s[-1].isdigit()])\n",
    "\n",
    "# Identifing complex words\n",
    "w_tokens = [i for i in word_tokens if i in cmud]\n",
    "complex_words = [word for word in w_tokens if count_syllables(word) > 2]\n",
    "\n",
    "# Calculatingnumber of complex words\n",
    "num_complex_words = len(complex_words)\n",
    "\n",
    "print(\"complex word count:\", num_complex_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ea5188",
   "metadata": {},
   "source": [
    "# Word Count\n",
    "number of words after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4fb0c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "380"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8076ff",
   "metadata": {},
   "source": [
    "# Syllable Count Per Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc568045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a word to get syllable: successful\n",
      "Number of syllable in a word : 3\n"
     ]
    }
   ],
   "source": [
    "word = input(\"Enter a word to get syllable: \")\n",
    "def count_syllables(word):\n",
    "    phonemes = cmud[word.lower()][0] \n",
    "    return len([s for s in phonemes if s[-1].isdigit()])\n",
    "\n",
    "print(\"Number of syllable in a word :\",count_syllables(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3a18f6",
   "metadata": {},
   "source": [
    "# Personal Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b8e0d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Personal pronoun frequency: {'we': 2, 'they': 4, 'it': 11, 'me': 1, 'you': 15}\n",
      "total number of pronouns in a article : 33\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define a regex pattern to match personal pronouns\n",
    "pattern = r'\\b(I|you|he|she|it|we|they|me|him|her|us|them)\\b'\n",
    "\n",
    "# Count the frequency of personal pronouns\n",
    "pronoun_freq = {}\n",
    "for pronoun in re.findall(pattern, texts, re.IGNORECASE):\n",
    "    pronoun = pronoun.lower()\n",
    "    if pronoun in pronoun_freq:\n",
    "        pronoun_freq[pronoun] += 1\n",
    "    else:\n",
    "        pronoun_freq[pronoun] = 1\n",
    "\n",
    "print(\"Personal pronoun frequency:\", pronoun_freq)\n",
    "def returnSum(dict):\n",
    " \n",
    "    sum = 0\n",
    "    for i in pronoun_freq.values():\n",
    "        sum = sum + i\n",
    " \n",
    "    return sum\n",
    "print(\"total number of pronouns in a article :\",returnSum(pronoun_freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fc87f8",
   "metadata": {},
   "source": [
    "# Average Word Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5bde37d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word length: 4.49\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total number of characters in all words\n",
    "total_chars = sum(len(word) for word in word_tokens)\n",
    "\n",
    "avg_word_length = total_chars / No_of_words\n",
    "\n",
    "print(\"Average word length:\", round(avg_word_length,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dc25ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819012c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
