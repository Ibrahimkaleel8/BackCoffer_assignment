{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9312f26",
   "metadata": {},
   "source": [
    "# Data scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef4785ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac2f2459",
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.get(\"https://insights.blackcoffer.com/will-machine-replace-the-human-in-the-future-of-work/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45f9fa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(req.content, \"html.parser\")\n",
    "res = soup.title\n",
    "paras = soup.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbb256b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“Anything that could give rise to smarter-than-human intelligence – in the form of Artificial Intelligence, brain-computer interfaces, or neuroscience-based human intelligence enhancement – wins hands down beyond contest as doing the most to change the world. Nothing else is even in the same league.” –Eliezer Yudkowsky, AI Researcher There’s no denying robots and automation are increasingly part of our daily lives. Just look around the grocery store, or the highway, they are everywhere. This makes us wonder what if AI can replace human intelligence? What can we do to make ourselves relevant tomorrow? Let us try to find the answers to all these questions and more. Let’s first understand what is Artificial Intelligence – Artificial Intelligence or AI basically machines displaying intelligence. This can be seen from a machine playing chess or a robot answering questions on Facebook. Artificial Intelligence can be further broken down into many different types. There are AIs designed to do specific tasks, such as detecting a specific type of cancer. However, there are also AIs that can do multiple tasks, such as driving a car. There are many types of AIs. Among the top, most important fields are Machine Learning or ML, Neural Network, Computer Vision, and Natural Language Processing or NLP. Machine Learning is the idea of machines being able to prove themselves similar to how a human being learns a new skill. Machine Learning also allows for the optimization of an existing skill. Machine Learning is used in many different fields and one such application is entertainment. Netflix uses Machine Learning to recommend more shows that you can watch based on the shows that you have already seen. Neural Networks are algorithms that are modeled after the human brain. These algorithms think just like we do which can thereby give similar results to what a human being can give. Artificial Neural Networks are used in medical fields to diagnose cancers like lung cancer and prostate cancer. Computer Vision is the idea that computers have visions. This allows them to see things the way human beings do or potentially better than human beings do, depending on the programming, camera used, etc. Computer Vision is used in autonomous vehicles for navigation from one place to another. Natural Language Processing is the idea that computers can listen to what we say. An example of this is Siri. Siri is able to listen to our demands, process what it means, and provide you an answer based on what is researched. Now that we know what an AI is and what it can do, Let’s talk about the issue. AIs allow for the automation of jobs, thereby replacing what humans already do. This means more job loss and the concentration of wealth to the selected few people. This could mean a destabilization of society and social unrest. In addition to social unrest, AI improves over time. This means it becomes smarter, faster, and cheaper to implement and it will be better at doing repetitive things that humans currently do, such as preparing fast food. It is predicted that AI will improve so much over 50 to 100 years that AI will become super intelligent. This means that it will become even smarter than the most intelligent human on earth. According to many experts such as Elon Musk, this could cause the end of human civilization. AI could potentially start a war against humans, burn crops and do all sorts of tragedies once reserved for human functions. At that point, in theory, we can not stop it because AI would have already thought of all the obstacles that will prevent its goal. This means that we cannot unplug the machine, in effect AI will replace human intelligence. But, will this happen in next 10 to 30 years? NO! The field of Artificial Intelligence is sophisticated enough to do many human tasks that humans currently do. Currently, AI is not smart enough to be empathetic to humans and cannot think strategically enough to solve complex problems. AI solutions can be expensive and have to go through many different tests and standards to implement. It also takes time for AI to improve. For example, Boston Dynamics, one of the world’s top robotics company had a robot in 2009 that needed assistance to walk. Fast forward to 2019, not only the robot could walk by itself but it could jump over objects, do backflips and so much more. In addition to the timing, it takes time for the price of any new technological solution to drop to a point where it is affordable. For example, a desktop computer costs around $1000 in 1999 but now you can get a significantly more powerful laptop for the exact same price. AI will go through the same curve. But what happens after those 10 to 30 years? Will AI make human intelligence obsolete? Maybe. As we have proven earlier AI will become faster better and cheaper. As this happens, more and more companies will use AI technology to automate more and more jobs to save money, increase productivity, and most importantly, stay competitive. As we have demonstrated, AI will become better through repetition via the use of machine learning. The only difference is that AI will be able to learn faster as time progresses due to the amount of data that is available today. It will also be able to learn from other machines or similar machines to learn how to optimize its tasks or new important skills. However, AI also just not do repetitive and routine tasks better, it will also be able to understand emotional intelligence, ethics, and creativity. This seen in three distinct example- IBM IBM uses its IBM Watson to program the AI to create a movie trailer. Fox approached IBM and said they have a movie coming out on AI #Scifi horror. They asked IBM if their platform IBM Watson could a trailer by reviewing and watching the footage and searching for scary, Sad or happy or other moments in the movie that provoked quality emotions based on how the machine was programmed to identify such emotions in a quantifiable manner. IBM Watson was able to generate a trailer for the movie Morgan. The result, a movie trailer created by machines example – Google IN 2018 google demonstrated an AI assistance that could take calls and do simple stuff. The AI was able to set up an appointment! What was more fascinating was that it was able to understand the nuances of the conversation. The receptionist thought it was a human being that was calling her. That is a very primitive version of what is possible with this technology. Eventually, it will be able to have conversations just as human beings do, making many sales jobs obsolete. example – AI generated art In 2018, a Paris art collective consisting of three students used artificial intelligence to generate a portrait. It generated the portrait painting by studying a set of fifteen thousand art images on wiki art. It was estimated to be worth between seven thousand to ten thousand dollars. The painting sold at an auction for four thirty-five thousand US dollars. However, we cannot for sure say that AI will replace human intelligence. This is because we as a society have started asking hard questions and questioning ethics. Elon Musk founded Open AI, a research lab whose whole purpose is to promote and discover artificial intelligence in a way to benefits humanity. In addition to this, there are many factors that affect the long-term outcome of AI replacing human intelligence. Like, to what degree will other humans allow for AI to take over? Depending on the field, do people even want Artificial Intelligence to help them? Or will they prefer a human counterpart? While we may not be able to control what happens in the long run, we can definitely secure our short-term future. Strategic and creative thinking The ability to think outside the box is very human. There are thousands upon thousands of slightly different possible outcomes that may result from every distinguishable action that the human mind with its ability to judge from experience is programmed for these purposes in a far more sophisticated manner than AI can currently achieve. As the billionaire founder of Alibaba, Jack Ma famously said – “AI has logic, human beings have wisdom”. Conflict resolution and negotiations With our understanding of the complexities of human-related processes and our ability to improvise and judge, we are far better equipped to deal with conflicts than robots are ever likely to be. AI may be able to recognize faces and images but it can rarely successfully read the feelings of those faces. Humans, to lesser or greater degrees, are capable of an accurate analysis of emotional subtext. With the application of intuition and the use of delicately worded or elusive languages, through these methods, we are able to properly judge how a person feels. Interpretation of Gray Areas Robots and computers function well when presented with quantifiable data. However, once the situation enters a gray area, whether this term refers to morals, processes, or definitions robots are more likely to falter. Critical thinking Humans are capable of responding to more indicators of quality than computers are. While an AI system may be able to analyze documents according to the true or false statements made within the text, we can judge whether or not it is well written and analyze the implication of the use of certain words and the overall meaning of the content. \n"
     ]
    }
   ],
   "source": [
    "texts = \" \".join([paragraph.text.strip() for paragraph in paras])\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e79f5f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9390"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8f1fcc",
   "metadata": {},
   "source": [
    "Removing Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5285c8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9390"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "texts = re.sub(r'[\\'\\“\\”\\()\\%\\,\\-\\'\\’\\?\\ ]', ' ', texts)\n",
    "texts[0:200]\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fafe7be",
   "metadata": {},
   "source": [
    "# Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "089b8663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "280876b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Anything',\n",
       " 'that',\n",
       " 'could',\n",
       " 'give',\n",
       " 'rise',\n",
       " 'to',\n",
       " 'smarter',\n",
       " 'than',\n",
       " 'human',\n",
       " 'intelligence',\n",
       " '–',\n",
       " 'in',\n",
       " 'the',\n",
       " 'form',\n",
       " 'of',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " 'brain',\n",
       " 'computer',\n",
       " 'interfaces',\n",
       " 'or',\n",
       " 'neuroscience',\n",
       " 'based',\n",
       " 'human',\n",
       " 'intelligence',\n",
       " 'enhancement',\n",
       " '–',\n",
       " 'wins',\n",
       " 'hands',\n",
       " 'down',\n",
       " 'beyond',\n",
       " 'contest',\n",
       " 'as',\n",
       " 'doing',\n",
       " 'the',\n",
       " 'most',\n",
       " 'to',\n",
       " 'change',\n",
       " 'the',\n",
       " 'world',\n",
       " '.',\n",
       " 'Nothing',\n",
       " 'else',\n",
       " 'is',\n",
       " 'even',\n",
       " 'in',\n",
       " 'the',\n",
       " 'same',\n",
       " 'league',\n",
       " '.',\n",
       " '–Eliezer',\n",
       " 'Yudkowsky',\n",
       " 'AI',\n",
       " 'Researcher',\n",
       " 'There',\n",
       " 's',\n",
       " 'no',\n",
       " 'denying',\n",
       " 'robots',\n",
       " 'and',\n",
       " 'automation',\n",
       " 'are',\n",
       " 'increasingly',\n",
       " 'part',\n",
       " 'of',\n",
       " 'our',\n",
       " 'daily',\n",
       " 'lives',\n",
       " '.',\n",
       " 'Just',\n",
       " 'look',\n",
       " 'around',\n",
       " 'the',\n",
       " 'grocery',\n",
       " 'store',\n",
       " 'or',\n",
       " 'the',\n",
       " 'highway',\n",
       " 'they',\n",
       " 'are',\n",
       " 'everywhere',\n",
       " '.',\n",
       " 'This',\n",
       " 'makes',\n",
       " 'us',\n",
       " 'wonder',\n",
       " 'what',\n",
       " 'if',\n",
       " 'AI',\n",
       " 'can',\n",
       " 'replace',\n",
       " 'human',\n",
       " 'intelligence',\n",
       " 'What',\n",
       " 'can',\n",
       " 'we',\n",
       " 'do',\n",
       " 'to',\n",
       " 'make',\n",
       " 'ourselves',\n",
       " 'relevant',\n",
       " 'tomorrow',\n",
       " 'Let',\n",
       " 'us',\n",
       " 'try',\n",
       " 'to',\n",
       " 'find',\n",
       " 'the',\n",
       " 'answers',\n",
       " 'to',\n",
       " 'all',\n",
       " 'these',\n",
       " 'questions',\n",
       " 'and',\n",
       " 'more',\n",
       " '.',\n",
       " 'Let',\n",
       " 's',\n",
       " 'first',\n",
       " 'understand',\n",
       " 'what',\n",
       " 'is',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " '–',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " 'or',\n",
       " 'AI',\n",
       " 'basically',\n",
       " 'machines',\n",
       " 'displaying',\n",
       " 'intelligence',\n",
       " '.',\n",
       " 'This',\n",
       " 'can',\n",
       " 'be',\n",
       " 'seen',\n",
       " 'from',\n",
       " 'a',\n",
       " 'machine',\n",
       " 'playing',\n",
       " 'chess',\n",
       " 'or',\n",
       " 'a',\n",
       " 'robot',\n",
       " 'answering',\n",
       " 'questions',\n",
       " 'on',\n",
       " 'Facebook',\n",
       " '.',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " 'can',\n",
       " 'be',\n",
       " 'further',\n",
       " 'broken',\n",
       " 'down',\n",
       " 'into',\n",
       " 'many',\n",
       " 'different',\n",
       " 'types',\n",
       " '.',\n",
       " 'There',\n",
       " 'are',\n",
       " 'AIs',\n",
       " 'designed',\n",
       " 'to',\n",
       " 'do',\n",
       " 'specific',\n",
       " 'tasks',\n",
       " 'such',\n",
       " 'as',\n",
       " 'detecting',\n",
       " 'a',\n",
       " 'specific',\n",
       " 'type',\n",
       " 'of',\n",
       " 'cancer',\n",
       " '.',\n",
       " 'However',\n",
       " 'there',\n",
       " 'are',\n",
       " 'also',\n",
       " 'AIs',\n",
       " 'that',\n",
       " 'can',\n",
       " 'do',\n",
       " 'multiple',\n",
       " 'tasks',\n",
       " 'such',\n",
       " 'as',\n",
       " 'driving',\n",
       " 'a',\n",
       " 'car',\n",
       " '.',\n",
       " 'There',\n",
       " 'are',\n",
       " 'many',\n",
       " 'types',\n",
       " 'of',\n",
       " 'AIs',\n",
       " '.',\n",
       " 'Among',\n",
       " 'the',\n",
       " 'top',\n",
       " 'most',\n",
       " 'important',\n",
       " 'fields',\n",
       " 'are',\n",
       " 'Machine',\n",
       " 'Learning',\n",
       " 'or',\n",
       " 'ML',\n",
       " 'Neural',\n",
       " 'Network',\n",
       " 'Computer',\n",
       " 'Vision',\n",
       " 'and',\n",
       " 'Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " 'or',\n",
       " 'NLP',\n",
       " '.',\n",
       " 'Machine',\n",
       " 'Learning',\n",
       " 'is',\n",
       " 'the',\n",
       " 'idea',\n",
       " 'of',\n",
       " 'machines',\n",
       " 'being',\n",
       " 'able',\n",
       " 'to',\n",
       " 'prove',\n",
       " 'themselves',\n",
       " 'similar',\n",
       " 'to',\n",
       " 'how',\n",
       " 'a',\n",
       " 'human',\n",
       " 'being',\n",
       " 'learns',\n",
       " 'a',\n",
       " 'new',\n",
       " 'skill',\n",
       " '.',\n",
       " 'Machine',\n",
       " 'Learning',\n",
       " 'also',\n",
       " 'allows',\n",
       " 'for',\n",
       " 'the',\n",
       " 'optimization',\n",
       " 'of',\n",
       " 'an',\n",
       " 'existing',\n",
       " 'skill',\n",
       " '.',\n",
       " 'Machine',\n",
       " 'Learning',\n",
       " 'is',\n",
       " 'used',\n",
       " 'in',\n",
       " 'many',\n",
       " 'different',\n",
       " 'fields',\n",
       " 'and',\n",
       " 'one',\n",
       " 'such',\n",
       " 'application',\n",
       " 'is',\n",
       " 'entertainment',\n",
       " '.',\n",
       " 'Netflix',\n",
       " 'uses',\n",
       " 'Machine',\n",
       " 'Learning',\n",
       " 'to',\n",
       " 'recommend',\n",
       " 'more',\n",
       " 'shows',\n",
       " 'that',\n",
       " 'you',\n",
       " 'can',\n",
       " 'watch',\n",
       " 'based',\n",
       " 'on',\n",
       " 'the',\n",
       " 'shows',\n",
       " 'that',\n",
       " 'you',\n",
       " 'have',\n",
       " 'already',\n",
       " 'seen',\n",
       " '.',\n",
       " 'Neural',\n",
       " 'Networks',\n",
       " 'are',\n",
       " 'algorithms',\n",
       " 'that',\n",
       " 'are',\n",
       " 'modeled',\n",
       " 'after',\n",
       " 'the',\n",
       " 'human',\n",
       " 'brain',\n",
       " '.',\n",
       " 'These',\n",
       " 'algorithms',\n",
       " 'think',\n",
       " 'just',\n",
       " 'like',\n",
       " 'we',\n",
       " 'do',\n",
       " 'which',\n",
       " 'can',\n",
       " 'thereby',\n",
       " 'give',\n",
       " 'similar',\n",
       " 'results',\n",
       " 'to',\n",
       " 'what',\n",
       " 'a',\n",
       " 'human',\n",
       " 'being',\n",
       " 'can',\n",
       " 'give',\n",
       " '.',\n",
       " 'Artificial',\n",
       " 'Neural',\n",
       " 'Networks',\n",
       " 'are',\n",
       " 'used',\n",
       " 'in',\n",
       " 'medical',\n",
       " 'fields',\n",
       " 'to',\n",
       " 'diagnose',\n",
       " 'cancers',\n",
       " 'like',\n",
       " 'lung',\n",
       " 'cancer',\n",
       " 'and',\n",
       " 'prostate',\n",
       " 'cancer',\n",
       " '.',\n",
       " 'Computer',\n",
       " 'Vision',\n",
       " 'is',\n",
       " 'the',\n",
       " 'idea',\n",
       " 'that',\n",
       " 'computers',\n",
       " 'have',\n",
       " 'visions',\n",
       " '.',\n",
       " 'This',\n",
       " 'allows',\n",
       " 'them',\n",
       " 'to',\n",
       " 'see',\n",
       " 'things',\n",
       " 'the',\n",
       " 'way',\n",
       " 'human',\n",
       " 'beings',\n",
       " 'do',\n",
       " 'or',\n",
       " 'potentially',\n",
       " 'better',\n",
       " 'than',\n",
       " 'human',\n",
       " 'beings',\n",
       " 'do',\n",
       " 'depending',\n",
       " 'on',\n",
       " 'the',\n",
       " 'programming',\n",
       " 'camera',\n",
       " 'used',\n",
       " 'etc',\n",
       " '.',\n",
       " 'Computer',\n",
       " 'Vision',\n",
       " 'is',\n",
       " 'used',\n",
       " 'in',\n",
       " 'autonomous',\n",
       " 'vehicles',\n",
       " 'for',\n",
       " 'navigation',\n",
       " 'from',\n",
       " 'one',\n",
       " 'place',\n",
       " 'to',\n",
       " 'another',\n",
       " '.',\n",
       " 'Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " 'is',\n",
       " 'the',\n",
       " 'idea',\n",
       " 'that',\n",
       " 'computers',\n",
       " 'can',\n",
       " 'listen',\n",
       " 'to',\n",
       " 'what',\n",
       " 'we',\n",
       " 'say',\n",
       " '.',\n",
       " 'An',\n",
       " 'example',\n",
       " 'of',\n",
       " 'this',\n",
       " 'is',\n",
       " 'Siri',\n",
       " '.',\n",
       " 'Siri',\n",
       " 'is',\n",
       " 'able',\n",
       " 'to',\n",
       " 'listen',\n",
       " 'to',\n",
       " 'our',\n",
       " 'demands',\n",
       " 'process',\n",
       " 'what',\n",
       " 'it',\n",
       " 'means',\n",
       " 'and',\n",
       " 'provide',\n",
       " 'you',\n",
       " 'an',\n",
       " 'answer',\n",
       " 'based',\n",
       " 'on',\n",
       " 'what',\n",
       " 'is',\n",
       " 'researched',\n",
       " '.',\n",
       " 'Now',\n",
       " 'that',\n",
       " 'we',\n",
       " 'know',\n",
       " 'what',\n",
       " 'an',\n",
       " 'AI',\n",
       " 'is',\n",
       " 'and',\n",
       " 'what',\n",
       " 'it',\n",
       " 'can',\n",
       " 'do',\n",
       " 'Let',\n",
       " 's',\n",
       " 'talk',\n",
       " 'about',\n",
       " 'the',\n",
       " 'issue',\n",
       " '.',\n",
       " 'AIs',\n",
       " 'allow',\n",
       " 'for',\n",
       " 'the',\n",
       " 'automation',\n",
       " 'of',\n",
       " 'jobs',\n",
       " 'thereby',\n",
       " 'replacing',\n",
       " 'what',\n",
       " 'humans',\n",
       " 'already',\n",
       " 'do',\n",
       " '.',\n",
       " 'This',\n",
       " 'means',\n",
       " 'more',\n",
       " 'job',\n",
       " 'loss',\n",
       " 'and',\n",
       " 'the',\n",
       " 'concentration',\n",
       " 'of',\n",
       " 'wealth',\n",
       " 'to',\n",
       " 'the',\n",
       " 'selected',\n",
       " 'few',\n",
       " 'people',\n",
       " '.',\n",
       " 'This',\n",
       " 'could',\n",
       " 'mean',\n",
       " 'a',\n",
       " 'destabilization',\n",
       " 'of',\n",
       " 'society',\n",
       " 'and',\n",
       " 'social',\n",
       " 'unrest',\n",
       " '.',\n",
       " 'In',\n",
       " 'addition',\n",
       " 'to',\n",
       " 'social',\n",
       " 'unrest',\n",
       " 'AI',\n",
       " 'improves',\n",
       " 'over',\n",
       " 'time',\n",
       " '.',\n",
       " 'This',\n",
       " 'means',\n",
       " 'it',\n",
       " 'becomes',\n",
       " 'smarter',\n",
       " 'faster',\n",
       " 'and',\n",
       " 'cheaper',\n",
       " 'to',\n",
       " 'implement',\n",
       " 'and',\n",
       " 'it',\n",
       " 'will',\n",
       " 'be',\n",
       " 'better',\n",
       " 'at',\n",
       " 'doing',\n",
       " 'repetitive',\n",
       " 'things',\n",
       " 'that',\n",
       " 'humans',\n",
       " 'currently',\n",
       " 'do',\n",
       " 'such',\n",
       " 'as',\n",
       " 'preparing',\n",
       " 'fast',\n",
       " 'food',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'predicted',\n",
       " 'that',\n",
       " 'AI',\n",
       " 'will',\n",
       " 'improve',\n",
       " 'so',\n",
       " 'much',\n",
       " 'over',\n",
       " '50',\n",
       " 'to',\n",
       " '100',\n",
       " 'years',\n",
       " 'that',\n",
       " 'AI',\n",
       " 'will',\n",
       " 'become',\n",
       " 'super',\n",
       " 'intelligent',\n",
       " '.',\n",
       " 'This',\n",
       " 'means',\n",
       " 'that',\n",
       " 'it',\n",
       " 'will',\n",
       " 'become',\n",
       " 'even',\n",
       " 'smarter',\n",
       " 'than',\n",
       " 'the',\n",
       " 'most',\n",
       " 'intelligent',\n",
       " 'human',\n",
       " 'on',\n",
       " 'earth',\n",
       " '.',\n",
       " 'According',\n",
       " 'to',\n",
       " 'many',\n",
       " 'experts',\n",
       " 'such',\n",
       " 'as',\n",
       " 'Elon',\n",
       " 'Musk',\n",
       " 'this',\n",
       " 'could',\n",
       " 'cause',\n",
       " 'the',\n",
       " 'end',\n",
       " 'of',\n",
       " 'human',\n",
       " 'civilization',\n",
       " '.',\n",
       " 'AI',\n",
       " 'could',\n",
       " 'potentially',\n",
       " 'start',\n",
       " 'a',\n",
       " 'war',\n",
       " 'against',\n",
       " 'humans',\n",
       " 'burn',\n",
       " 'crops',\n",
       " 'and',\n",
       " 'do',\n",
       " 'all',\n",
       " 'sorts',\n",
       " 'of',\n",
       " 'tragedies',\n",
       " 'once',\n",
       " 'reserved',\n",
       " 'for',\n",
       " 'human',\n",
       " 'functions',\n",
       " '.',\n",
       " 'At',\n",
       " 'that',\n",
       " 'point',\n",
       " 'in',\n",
       " 'theory',\n",
       " 'we',\n",
       " 'can',\n",
       " 'not',\n",
       " 'stop',\n",
       " 'it',\n",
       " 'because',\n",
       " 'AI',\n",
       " 'would',\n",
       " 'have',\n",
       " 'already',\n",
       " 'thought',\n",
       " 'of',\n",
       " 'all',\n",
       " 'the',\n",
       " 'obstacles',\n",
       " 'that',\n",
       " 'will',\n",
       " 'prevent',\n",
       " 'its',\n",
       " 'goal',\n",
       " '.',\n",
       " 'This',\n",
       " 'means',\n",
       " 'that',\n",
       " 'we',\n",
       " 'can',\n",
       " 'not',\n",
       " 'unplug',\n",
       " 'the',\n",
       " 'machine',\n",
       " 'in',\n",
       " 'effect',\n",
       " 'AI',\n",
       " 'will',\n",
       " 'replace',\n",
       " 'human',\n",
       " 'intelligence',\n",
       " '.',\n",
       " 'But',\n",
       " 'will',\n",
       " 'this',\n",
       " 'happen',\n",
       " 'in',\n",
       " 'next',\n",
       " '10',\n",
       " 'to',\n",
       " '30',\n",
       " 'years',\n",
       " 'NO',\n",
       " '!',\n",
       " 'The',\n",
       " 'field',\n",
       " 'of',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " 'is',\n",
       " 'sophisticated',\n",
       " 'enough',\n",
       " 'to',\n",
       " 'do',\n",
       " 'many',\n",
       " 'human',\n",
       " 'tasks',\n",
       " 'that',\n",
       " 'humans',\n",
       " 'currently',\n",
       " 'do',\n",
       " '.',\n",
       " 'Currently',\n",
       " 'AI',\n",
       " 'is',\n",
       " 'not',\n",
       " 'smart',\n",
       " 'enough',\n",
       " 'to',\n",
       " 'be',\n",
       " 'empathetic',\n",
       " 'to',\n",
       " 'humans',\n",
       " 'and',\n",
       " 'can',\n",
       " 'not',\n",
       " 'think',\n",
       " 'strategically',\n",
       " 'enough',\n",
       " 'to',\n",
       " 'solve',\n",
       " 'complex',\n",
       " 'problems',\n",
       " '.',\n",
       " 'AI',\n",
       " 'solutions',\n",
       " 'can',\n",
       " 'be',\n",
       " 'expensive',\n",
       " 'and',\n",
       " 'have',\n",
       " 'to',\n",
       " 'go',\n",
       " 'through',\n",
       " 'many',\n",
       " 'different',\n",
       " 'tests',\n",
       " 'and',\n",
       " 'standards',\n",
       " 'to',\n",
       " 'implement',\n",
       " '.',\n",
       " 'It',\n",
       " 'also',\n",
       " 'takes',\n",
       " 'time',\n",
       " 'for',\n",
       " 'AI',\n",
       " 'to',\n",
       " 'improve',\n",
       " '.',\n",
       " 'For',\n",
       " 'example',\n",
       " 'Boston',\n",
       " 'Dynamics',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'world',\n",
       " 's',\n",
       " 'top',\n",
       " 'robotics',\n",
       " 'company',\n",
       " 'had',\n",
       " 'a',\n",
       " 'robot',\n",
       " 'in',\n",
       " '2009',\n",
       " 'that',\n",
       " 'needed',\n",
       " 'assistance',\n",
       " 'to',\n",
       " 'walk',\n",
       " '.',\n",
       " 'Fast',\n",
       " 'forward',\n",
       " 'to',\n",
       " '2019',\n",
       " 'not',\n",
       " 'only',\n",
       " 'the',\n",
       " 'robot',\n",
       " 'could',\n",
       " 'walk',\n",
       " 'by',\n",
       " 'itself',\n",
       " 'but',\n",
       " 'it',\n",
       " 'could',\n",
       " 'jump',\n",
       " 'over',\n",
       " 'objects',\n",
       " 'do',\n",
       " 'backflips',\n",
       " 'and',\n",
       " 'so',\n",
       " 'much',\n",
       " 'more',\n",
       " '.',\n",
       " 'In',\n",
       " 'addition',\n",
       " 'to',\n",
       " 'the',\n",
       " 'timing',\n",
       " 'it',\n",
       " 'takes',\n",
       " 'time',\n",
       " 'for',\n",
       " 'the',\n",
       " 'price',\n",
       " 'of',\n",
       " 'any',\n",
       " 'new',\n",
       " 'technological',\n",
       " 'solution',\n",
       " 'to',\n",
       " 'drop',\n",
       " 'to',\n",
       " 'a',\n",
       " 'point',\n",
       " 'where',\n",
       " 'it',\n",
       " 'is',\n",
       " 'affordable',\n",
       " '.',\n",
       " 'For',\n",
       " 'example',\n",
       " 'a',\n",
       " 'desktop',\n",
       " 'computer',\n",
       " 'costs',\n",
       " 'around',\n",
       " '$',\n",
       " '1000',\n",
       " 'in',\n",
       " '1999',\n",
       " 'but',\n",
       " 'now',\n",
       " 'you',\n",
       " 'can',\n",
       " 'get',\n",
       " 'a',\n",
       " 'significantly',\n",
       " 'more',\n",
       " 'powerful',\n",
       " 'laptop',\n",
       " 'for',\n",
       " 'the',\n",
       " 'exact',\n",
       " 'same',\n",
       " 'price',\n",
       " '.',\n",
       " 'AI',\n",
       " 'will',\n",
       " 'go',\n",
       " 'through',\n",
       " 'the',\n",
       " 'same',\n",
       " 'curve',\n",
       " '.',\n",
       " 'But',\n",
       " 'what',\n",
       " 'happens',\n",
       " 'after',\n",
       " 'those',\n",
       " '10',\n",
       " 'to',\n",
       " '30',\n",
       " 'years',\n",
       " 'Will',\n",
       " 'AI',\n",
       " 'make',\n",
       " 'human',\n",
       " 'intelligence',\n",
       " 'obsolete',\n",
       " 'Maybe',\n",
       " '.',\n",
       " 'As',\n",
       " 'we',\n",
       " 'have',\n",
       " 'proven',\n",
       " 'earlier',\n",
       " 'AI',\n",
       " 'will',\n",
       " 'become',\n",
       " 'faster',\n",
       " 'better',\n",
       " 'and',\n",
       " 'cheaper',\n",
       " '.',\n",
       " 'As',\n",
       " 'this',\n",
       " 'happens',\n",
       " 'more',\n",
       " 'and',\n",
       " 'more',\n",
       " 'companies',\n",
       " 'will',\n",
       " 'use',\n",
       " 'AI',\n",
       " 'technology',\n",
       " 'to',\n",
       " 'automate',\n",
       " 'more',\n",
       " 'and',\n",
       " 'more',\n",
       " 'jobs',\n",
       " 'to',\n",
       " 'save',\n",
       " 'money',\n",
       " 'increase',\n",
       " 'productivity',\n",
       " 'and',\n",
       " 'most',\n",
       " 'importantly',\n",
       " 'stay',\n",
       " 'competitive',\n",
       " '.',\n",
       " 'As',\n",
       " 'we',\n",
       " 'have',\n",
       " 'demonstrated',\n",
       " 'AI',\n",
       " 'will',\n",
       " 'become',\n",
       " 'better',\n",
       " 'through',\n",
       " 'repetition',\n",
       " 'via',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'machine',\n",
       " 'learning',\n",
       " '.',\n",
       " 'The',\n",
       " 'only',\n",
       " 'difference',\n",
       " 'is',\n",
       " 'that',\n",
       " 'AI',\n",
       " 'will',\n",
       " 'be',\n",
       " 'able',\n",
       " 'to',\n",
       " 'learn',\n",
       " 'faster',\n",
       " 'as',\n",
       " 'time',\n",
       " 'progresses',\n",
       " 'due',\n",
       " 'to',\n",
       " 'the',\n",
       " 'amount',\n",
       " 'of',\n",
       " 'data',\n",
       " 'that',\n",
       " 'is',\n",
       " 'available',\n",
       " 'today',\n",
       " '.',\n",
       " 'It',\n",
       " 'will',\n",
       " 'also',\n",
       " 'be',\n",
       " 'able',\n",
       " 'to',\n",
       " 'learn',\n",
       " 'from',\n",
       " 'other',\n",
       " 'machines',\n",
       " 'or',\n",
       " 'similar',\n",
       " 'machines',\n",
       " 'to',\n",
       " 'learn',\n",
       " 'how',\n",
       " 'to',\n",
       " 'optimize',\n",
       " 'its',\n",
       " 'tasks',\n",
       " 'or',\n",
       " 'new',\n",
       " 'important',\n",
       " 'skills',\n",
       " '.',\n",
       " 'However',\n",
       " 'AI',\n",
       " 'also',\n",
       " 'just',\n",
       " 'not',\n",
       " 'do',\n",
       " 'repetitive',\n",
       " 'and',\n",
       " 'routine',\n",
       " 'tasks',\n",
       " 'better',\n",
       " 'it',\n",
       " 'will',\n",
       " 'also',\n",
       " 'be',\n",
       " 'able',\n",
       " 'to',\n",
       " 'understand',\n",
       " 'emotional',\n",
       " 'intelligence',\n",
       " 'ethics',\n",
       " 'and',\n",
       " 'creativity',\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = word_tokenize(texts)\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10016a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"D:\\lab\\Dataset\\Stopwords_Blackcoffer.txt\", 'r') as file:\n",
    "    data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c567cbef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ERNST\\nYOUNG\\nDELOITTE\\nTOUCHE\\nKPMG\\nPRICEWATERHOUSECOOPERS\\nPRICEWATERHOUSE\\nCOOPERS\\nAFGHANI\\nARIARY\\nBAHT\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d65bfa92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ERNST,YOUNG,DELOITTE,TOUCHE,KPMG,PRICEWATERHOUSECOOPERS,PRICEWATERHOUSE,COOPERS,AFGHANI,ARIARY,BAHT,'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.replace('\\n', ',')\n",
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ef23874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Anything rise smarter human intelligence – Artificial Intelligence brain computer interfaces neuroscience based human intelligence enhancement – wins hands contest world . Nothing league . –Eliezer Yu'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_texts = \" \".join([i for i in token if i not in data])\n",
    "new_texts[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea392da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length before cleaning:  9390\n",
      "length after cleaning:  5565\n"
     ]
    }
   ],
   "source": [
    "print(\"length before cleaning: \", len(texts))\n",
    "print(\"length after cleaning: \", len(new_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f456147",
   "metadata": {},
   "source": [
    "# Negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc3618a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"D:\\\\lab\\\\Dataset\\\\Negative_words.txt\", 'r') as file:\n",
    "    negative = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2123c4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2-faced\\n2-faces\\nabnormal\\nabolish\\nabominable\\nabominably\\nabominate\\nabomination\\nabort\\naborted\\naborts\\nabrade\\nabrasive\\nabrupt\\nabruptly\\nabscond\\nabsence\\nabsent-minded\\nabsentee\\nabsurd\\nabsurdity\\nabsurdly\\nabsurdness\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative[:206]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28f44c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2-faced,2-faces,abnormal,abolish,abominable,abominably,abominate,abomination,abort,aborted,aborts,abrade,abrasive,abrupt,abruptly,abscond,absence,absent-minded,absentee,absurd,absurdity,absurdly,absurdness,'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative = negative.replace('\\n', ',')\n",
    "negative[:206]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31a272c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['human', 'brain', 'human', 'league', 'denying', 'human', 'make', 'relevant', 'understand', 'broken', 'designed', 'type', 'cancer', 'car', 'top', 'important', 'prove', 'human', 'skill', 'skill', 'watch', 'human', 'brain', 'human', 'cancer', 'cancer', 'human', 'human', 'issue', 'job', 'loss', 'social', 'unrest', 'social', 'unrest', 'repetitive', 'fast', 'super', 'human', 'earth', 'human', 'start', 'burn', 'human', 'point', 'thought', 'effect', 'human', 'sophisticated', 'human', 'solve', 'complex', 'problems', 'expensive', 'tests', 'takes', 'top', 'needed', 'jump', 'takes', 'price', 'solution', 'drop', 'point', 'affordable', 'significantly', 'price', 'make', 'human', 'obsolete', 'proven', 'competitive', 'difference', 'due', 'important', 'repetitive', 'understand', 'scary', 'happy', 'quality', 'manner', 'generate', 'stuff', 'set', 'appointment', 'understand', 'thought', 'human', 'primitive', 'version', 'human', 'obsolete', 'generate', 'set', 'worth', 'human', 'founded', 'humanity', 'affect', 'term', 'human', 'human', 'control', 'run', 'secure', 'short', 'term', 'creative', 'ability', 'box', 'human', 'distinguishable', 'action', 'human', 'mind', 'ability', 'judge', 'experience', 'sophisticated', 'manner', 'famously', 'logic', 'human', 'understanding', 'human', 'ability', 'judge', 'deal', 'conflicts', 'faces', 'successfully', 'faces', 'lesser', 'capable', 'accurate', 'properly', 'judge', 'person', 'term', 'falter', 'capable', 'quality', 'true', 'false', 'statements', 'judge', 'implication', 'meaning', 'content']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_texts = word_tokenize(new_texts)\n",
    "negative_words = [i for i in new_texts if i in negative]\n",
    "print(negative_words)\n",
    "len(negative_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b24f011",
   "metadata": {},
   "source": [
    "# Positive words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b003620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a+\\nabound\\nabounds\\nabundance\\nabundant\\naccessable\\naccessible\\nacclaim\\nacclaimed\\nacclamation\\naccolade\\naccolades\\naccommodative\\naccomodative\\naccomplish\\naccomplished\\naccomplishment\\naccomplishments\\naccurate\\naccurately\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"D:\\\\lab\\\\Dataset\\\\Positive_words.txt\", 'r') as file:\n",
    "    positive = file.read()\n",
    "positive[:210]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66ed38c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a+,abound,abounds,abundance,abundant,accessable,accessible,acclaim,acclaimed,acclamation,accolade,accolades,accommodative,accomodative,accomplish,accomplished,accomplishment,accomplishments,accurate,accurately,'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive = positive.replace('\\n',',')\n",
    "positive[:210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc1387e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['smarter', 'human', 'intelligence', 'brain', 'human', 'intelligence', 'enhancement', 'wins', 'hands', 'world', 'store', 'replace', 'human', 'intelligence', 'understand', 'intelligence', 'car', 'top', 'important', 'idea', 'prove', 'human', 'skill', 'skill', 'recommend', 'human', 'brain', 'human', 'idea', 'human', 'human', 'autonomous', 'idea', 'listen', 'listen', 'issue', 'loss', 'wealth', 'unrest', 'unrest', 'improves', 'smarter', 'faster', 'cheaper', 'fast', 'improve', 'super', 'intelligent', 'smarter', 'intelligent', 'human', 'human', 'human', 'thought', 'effect', 'replace', 'human', 'intelligence', 'sophisticated', 'human', 'smart', 'solve', 'expensive', 'takes', 'improve', 'world', 'top', 'forward', 'takes', 'price', 'drop', 'affordable', 'powerful', 'price', 'human', 'intelligence', 'proven', 'faster', 'cheaper', 'save', 'competitive', 'faster', 'amount', 'important', 'understand', 'intelligence', 'distinct', 'happy', 'quality', 'manner', 'simple', 'set', 'fascinating', 'understand', 'thought', 'human', 'human', 'intelligence', 'set', 'worth', 'replace', 'human', 'intelligence', 'founded', 'purpose', 'promote', 'intelligence', 'benefits', 'affect', 'term', 'human', 'intelligence', 'prefer', 'human', 'run', 'secure', 'term', 'future', 'creative', 'ability', 'human', 'action', 'human', 'mind', 'ability', 'sophisticated', 'manner', 'achieve', 'famously', 'logic', 'human', 'wisdom', 'human', 'ability', 'deal', 'successfully', 'capable', 'accurate', 'properly', 'person', 'term', 'refers', 'capable', 'quality', 'made', 'meaning', 'content']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_words = [i for i in new_texts if i in positive]\n",
    "print(positive_words)\n",
    "len(positive_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b59646d",
   "metadata": {},
   "source": [
    "#### positive Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d0fbab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n"
     ]
    }
   ],
   "source": [
    "pos_score = len(positive_words)\n",
    "print(pos_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a6cc12",
   "metadata": {},
   "source": [
    "#### Negative Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df0766cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n"
     ]
    }
   ],
   "source": [
    "neg_score=len(negative_words)\n",
    "print(neg_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84da7ab7",
   "metadata": {},
   "source": [
    "#### Polarity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21e88c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.01"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Polarity_Score = (pos_score - neg_score)/((pos_score + neg_score) + 0.000001)\n",
    "round(Polarity_Score,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16495ba1",
   "metadata": {},
   "source": [
    "#### Subjectivity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "841713a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Subjectivity_Score = (pos_score + neg_score)/ ((8860) + 0.000001)\n",
    "round(Subjectivity_Score,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7c370e",
   "metadata": {},
   "source": [
    "# Analysis of Readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10209a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1689"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "word_tokens = nltk.word_tokenize(texts)\n",
    "No_of_words = len(word_tokens)\n",
    "No_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bfac2ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokens = nltk.sent_tokenize(texts)\n",
    "No_of_sents = len(sent_tokens)\n",
    "No_of_sents "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1576acfe",
   "metadata": {},
   "source": [
    "### Average sentence Length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11d6a7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.11"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Avg_Sents_Length = No_of_words / No_of_sents\n",
    "round(Avg_Sents_Length,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc20ee3d",
   "metadata": {},
   "source": [
    "### Percentage of Complex words\n",
    "Complex words: words with more than 2 syllable are called complex words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eba6a8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of complex words: 216\n",
      "Total number of words: 9390\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import cmudict\n",
    "cmud = cmudict.dict()\n",
    "\n",
    "# Defining a function to count syllables in a word\n",
    "def count_syllables(word):\n",
    "    phonemes = cmud[word.lower()][0] \n",
    "    return len([s for s in phonemes if s[-1].isdigit()])\n",
    "\n",
    "# Identifing complex words\n",
    "w_tokens = [i for i in word_tokens if i in cmud]\n",
    "complex_words = [word for word in w_tokens if count_syllables(word) > 2]\n",
    "\n",
    "# Calculatingnumber of complex words\n",
    "num_complex_words = len(complex_words)\n",
    "\n",
    "print(\"Number of complex words:\", num_complex_words)\n",
    "print(\"Total number of words:\", len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f06ce4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.47"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Perc_of_Complex_words = len(texts) / num_complex_words\n",
    "round(Perc_of_Complex_words,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e948d1",
   "metadata": {},
   "source": [
    "### Fog Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95fb10bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sentence length: 84.0\n"
     ]
    }
   ],
   "source": [
    "# Tokenize each sentence into words\n",
    "words = [word_tokens for sentence in sent_tokens]\n",
    "\n",
    "# Calculate the average sentence length\n",
    "avg_sent_len = sum(No_of_sents for sentence in words) / No_of_sents\n",
    "\n",
    "print(\"Average sentence length:\", avg_sent_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38f5a93b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.99"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fog_index = 0.4 * (avg_sent_len + Perc_of_Complex_words)\n",
    "round(Fog_index,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4aacea",
   "metadata": {},
   "source": [
    "# Average Number of Words Per Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45da1407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.11"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_no_of_words_per_sent = No_of_words / No_of_sents\n",
    "round(avg_no_of_words_per_sent,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d9b493",
   "metadata": {},
   "source": [
    "# Complex Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "75304424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complex word count: 216\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import cmudict\n",
    "cmud = cmudict.dict()\n",
    "\n",
    "# Defining a function to count syllables in a word\n",
    "def count_syllables(word):\n",
    "    phonemes = cmud[word.lower()][0] \n",
    "    return len([s for s in phonemes if s[-1].isdigit()])\n",
    "\n",
    "# Identifing complex words\n",
    "w_tokens = [i for i in word_tokens if i in cmud]\n",
    "complex_words = [word for word in w_tokens if count_syllables(word) > 2]\n",
    "\n",
    "# Calculatingnumber of complex words\n",
    "num_complex_words = len(complex_words)\n",
    "\n",
    "print(\"complex word count:\", num_complex_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ea5188",
   "metadata": {},
   "source": [
    "# Word Count\n",
    "number of words after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4fb0c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "789"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8076ff",
   "metadata": {},
   "source": [
    "# Syllable Count Per Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc568045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a word to get syllable: creative\n",
      "Number of syllable in a word : 3\n"
     ]
    }
   ],
   "source": [
    "word = input(\"Enter a word to get syllable: \")\n",
    "def count_syllables(word):\n",
    "    phonemes = cmud[word.lower()][0] \n",
    "    return len([s for s in phonemes if s[-1].isdigit()])\n",
    "\n",
    "print(\"Number of syllable in a word :\",count_syllables(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3a18f6",
   "metadata": {},
   "source": [
    "# Personal Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b8e0d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Personal pronoun frequency: {'they': 4, 'us': 3, 'we': 15, 'you': 4, 'them': 2, 'it': 20, 'her': 1}\n",
      "total number of pronouns in a article : 49\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define a regex pattern to match personal pronouns\n",
    "pattern = r'\\b(I|you|he|she|it|we|they|me|him|her|us|them)\\b'\n",
    "\n",
    "# Count the frequency of personal pronouns\n",
    "pronoun_freq = {}\n",
    "for pronoun in re.findall(pattern, texts, re.IGNORECASE):\n",
    "    pronoun = pronoun.lower()\n",
    "    if pronoun in pronoun_freq:\n",
    "        pronoun_freq[pronoun] += 1\n",
    "    else:\n",
    "        pronoun_freq[pronoun] = 1\n",
    "\n",
    "print(\"Personal pronoun frequency:\", pronoun_freq)\n",
    "def returnSum(dict):\n",
    " \n",
    "    sum = 0\n",
    "    for i in pronoun_freq.values():\n",
    "        sum = sum + i\n",
    " \n",
    "    return sum\n",
    "print(\"total number of pronouns in a article :\",returnSum(pronoun_freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fc87f8",
   "metadata": {},
   "source": [
    "# Average Word Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5bde37d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word length: 4.56\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total number of characters in all words\n",
    "total_chars = sum(len(word) for word in word_tokens)\n",
    "\n",
    "avg_word_length = total_chars / No_of_words\n",
    "\n",
    "print(\"Average word length:\", round(avg_word_length,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcefd0d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32530c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
