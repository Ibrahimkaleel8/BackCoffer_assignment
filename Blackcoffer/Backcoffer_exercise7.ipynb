{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9312f26",
   "metadata": {},
   "source": [
    "# Data scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef4785ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac2f2459",
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.get(\"https://insights.blackcoffer.com/in-future-or-in-upcoming-years-humans-and-machines-are-going-to-work-together-in-every-field-of-work/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45f9fa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(req.content, \"html.parser\")\n",
    "res = soup.title\n",
    "paras = soup.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbb256b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In future or in upcoming years humans and machines are going to work together in every field of work. In upcoming days machines will be the need for every human being. Machines [AI technology] will do the work which humans are incapable of doing. Machines will partner and co-operate with humans. According to the professor at the university of Washington, he explained that, as a result of AI, there will be more demand for existing jobs and new jobs will be created that are unimaginable today. Human workers and machines will work together flawlessly, complementing each other. Machines will learn to carry out easier tasks such as following processes or crunching data. They will also help the humans while difficult. Machines or AI will create a great job opportunities for humans in future. John Kelly ll, executive vice president of IBM once said that “Man and Machines working together always beat or make a better decision than a man or a machine independently.” In future, the three sectors of our country like agriculture sector, industrial sector and service sector are going to utilize the machines. So, that their work becomes not difficult. As of now, we can only see that for agriculture purposes various kinds of machines are used which we called as a modern farming method. Some major technologies [machines] that are harvest automation, autonomous tractors, seeding, and weeing and drones. As a result, farms can do agriculture peacefully. In the industrial sector also humans and machines are working together to increase production. Various types of machines are used in industries such as packing machines, loading machine etc. humans provide instructions to the machines and maintain the management in the company. Soon robots [machines] will assist doctors with surgeries. For instance, a doctor at remote location could direct a surgical robot to perform an open heart surgery. But the approaches option and decision will be left to experience and wisdom of the doctor not the robot. What do you think of machines if they will make humans less or more in the field? Machines will push human professionals up the skillset ladder into uniquely human skills such as creativity, social abilities, empathy, and sense-making, which machines cannot automate. As a result, machines will make the workplace more, not less for humans. However, humans have to learn new skills throughout their lives. It is said that in the future 80% of process-oriented tasks will be done by machines. Quantitative reasoning tasks will be done approximately 50% by humans and 50% by machines, while humans will continue to do more than 80% of cross-functional reasoning tasks. According to Harvard research machines, algorithms can read diagnostic scans with 92% accuracy. Humans can do it with 96% accuracy. Together, it will be 99% accurate. Human-machine collaboration enables companies to interact with employees and customers in the novel, more effective ways. Smart machines are helping humans to expand their abilities in three ways. They can amplify our cognitive strengths; interact with customers and employees to free us from higher-level tasks, and embody human skills to extend our physical capabilities. In the research, it was found that 1,500 companies achieve the most significant performance improvement when humans and machines work together. New machine systems have beyond-human cognitive abilities, which many of us fear could potentially dehumanize the future of work. Machines will indeed automate most repetitive and physical tasks, and part of quantitative tasks such as programming and even data science. According to D.E Shaw Group and professor at the University of Washington, explained that, as a result of machines, there will be more demand for existing jobs, and new jobs will be created that are unimaginable today. This is similar to how we couldn’t imagine a web app developer decades ago, and now millions make a living doing that today. Machines are good at doing tasks with speed, precision, and accuracy. But machines are not very good at responding to unknown situations or making judgments. That part will be left to humans. Hence, the need for both humans and machines will be there in the future. Humans and machines have divergent skill sets that, when combined can transform the way we work. Machines have already infiltrated every aspect of our lives, and we must learn to live with them. In the future, human workers will interact more closely with humans. \n"
     ]
    }
   ],
   "source": [
    "texts = \" \".join([paragraph.text.strip() for paragraph in paras])\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e79f5f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4505"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8f1fcc",
   "metadata": {},
   "source": [
    "Removing Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5285c8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4505"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "texts = re.sub(r'[\\'\\“\\”\\()\\%\\,\\-\\'\\’\\?\\ ]', ' ', texts)\n",
    "texts[0:200]\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fafe7be",
   "metadata": {},
   "source": [
    "# Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "089b8663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "280876b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'future',\n",
       " 'or',\n",
       " 'in',\n",
       " 'upcoming',\n",
       " 'years',\n",
       " 'humans',\n",
       " 'and',\n",
       " 'machines',\n",
       " 'are',\n",
       " 'going',\n",
       " 'to',\n",
       " 'work',\n",
       " 'together',\n",
       " 'in',\n",
       " 'every',\n",
       " 'field',\n",
       " 'of',\n",
       " 'work',\n",
       " '.',\n",
       " 'In',\n",
       " 'upcoming',\n",
       " 'days',\n",
       " 'machines',\n",
       " 'will',\n",
       " 'be',\n",
       " 'the',\n",
       " 'need',\n",
       " 'for',\n",
       " 'every',\n",
       " 'human',\n",
       " 'being',\n",
       " '.',\n",
       " 'Machines',\n",
       " '[',\n",
       " 'AI',\n",
       " 'technology',\n",
       " ']',\n",
       " 'will',\n",
       " 'do',\n",
       " 'the',\n",
       " 'work',\n",
       " 'which',\n",
       " 'humans',\n",
       " 'are',\n",
       " 'incapable',\n",
       " 'of',\n",
       " 'doing',\n",
       " '.',\n",
       " 'Machines',\n",
       " 'will',\n",
       " 'partner',\n",
       " 'and',\n",
       " 'co',\n",
       " 'operate',\n",
       " 'with',\n",
       " 'humans',\n",
       " '.',\n",
       " 'According',\n",
       " 'to',\n",
       " 'the',\n",
       " 'professor',\n",
       " 'at',\n",
       " 'the',\n",
       " 'university',\n",
       " 'of',\n",
       " 'Washington',\n",
       " 'he',\n",
       " 'explained',\n",
       " 'that',\n",
       " 'as',\n",
       " 'a',\n",
       " 'result',\n",
       " 'of',\n",
       " 'AI',\n",
       " 'there',\n",
       " 'will',\n",
       " 'be',\n",
       " 'more',\n",
       " 'demand',\n",
       " 'for',\n",
       " 'existing',\n",
       " 'jobs',\n",
       " 'and',\n",
       " 'new',\n",
       " 'jobs',\n",
       " 'will',\n",
       " 'be',\n",
       " 'created',\n",
       " 'that',\n",
       " 'are',\n",
       " 'unimaginable',\n",
       " 'today',\n",
       " '.',\n",
       " 'Human',\n",
       " 'workers',\n",
       " 'and',\n",
       " 'machines',\n",
       " 'will',\n",
       " 'work',\n",
       " 'together',\n",
       " 'flawlessly',\n",
       " 'complementing',\n",
       " 'each',\n",
       " 'other',\n",
       " '.',\n",
       " 'Machines',\n",
       " 'will',\n",
       " 'learn',\n",
       " 'to',\n",
       " 'carry',\n",
       " 'out',\n",
       " 'easier',\n",
       " 'tasks',\n",
       " 'such',\n",
       " 'as',\n",
       " 'following',\n",
       " 'processes',\n",
       " 'or',\n",
       " 'crunching',\n",
       " 'data',\n",
       " '.',\n",
       " 'They',\n",
       " 'will',\n",
       " 'also',\n",
       " 'help',\n",
       " 'the',\n",
       " 'humans',\n",
       " 'while',\n",
       " 'difficult',\n",
       " '.',\n",
       " 'Machines',\n",
       " 'or',\n",
       " 'AI',\n",
       " 'will',\n",
       " 'create',\n",
       " 'a',\n",
       " 'great',\n",
       " 'job',\n",
       " 'opportunities',\n",
       " 'for',\n",
       " 'humans',\n",
       " 'in',\n",
       " 'future',\n",
       " '.',\n",
       " 'John',\n",
       " 'Kelly',\n",
       " 'll',\n",
       " 'executive',\n",
       " 'vice',\n",
       " 'president',\n",
       " 'of',\n",
       " 'IBM',\n",
       " 'once',\n",
       " 'said',\n",
       " 'that',\n",
       " 'Man',\n",
       " 'and',\n",
       " 'Machines',\n",
       " 'working',\n",
       " 'together',\n",
       " 'always',\n",
       " 'beat',\n",
       " 'or',\n",
       " 'make',\n",
       " 'a',\n",
       " 'better',\n",
       " 'decision',\n",
       " 'than',\n",
       " 'a',\n",
       " 'man',\n",
       " 'or',\n",
       " 'a',\n",
       " 'machine',\n",
       " 'independently',\n",
       " '.',\n",
       " 'In',\n",
       " 'future',\n",
       " 'the',\n",
       " 'three',\n",
       " 'sectors',\n",
       " 'of',\n",
       " 'our',\n",
       " 'country',\n",
       " 'like',\n",
       " 'agriculture',\n",
       " 'sector',\n",
       " 'industrial',\n",
       " 'sector',\n",
       " 'and',\n",
       " 'service',\n",
       " 'sector',\n",
       " 'are',\n",
       " 'going',\n",
       " 'to',\n",
       " 'utilize',\n",
       " 'the',\n",
       " 'machines',\n",
       " '.',\n",
       " 'So',\n",
       " 'that',\n",
       " 'their',\n",
       " 'work',\n",
       " 'becomes',\n",
       " 'not',\n",
       " 'difficult',\n",
       " '.',\n",
       " 'As',\n",
       " 'of',\n",
       " 'now',\n",
       " 'we',\n",
       " 'can',\n",
       " 'only',\n",
       " 'see',\n",
       " 'that',\n",
       " 'for',\n",
       " 'agriculture',\n",
       " 'purposes',\n",
       " 'various',\n",
       " 'kinds',\n",
       " 'of',\n",
       " 'machines',\n",
       " 'are',\n",
       " 'used',\n",
       " 'which',\n",
       " 'we',\n",
       " 'called',\n",
       " 'as',\n",
       " 'a',\n",
       " 'modern',\n",
       " 'farming',\n",
       " 'method',\n",
       " '.',\n",
       " 'Some',\n",
       " 'major',\n",
       " 'technologies',\n",
       " '[',\n",
       " 'machines',\n",
       " ']',\n",
       " 'that',\n",
       " 'are',\n",
       " 'harvest',\n",
       " 'automation',\n",
       " 'autonomous',\n",
       " 'tractors',\n",
       " 'seeding',\n",
       " 'and',\n",
       " 'weeing',\n",
       " 'and',\n",
       " 'drones',\n",
       " '.',\n",
       " 'As',\n",
       " 'a',\n",
       " 'result',\n",
       " 'farms',\n",
       " 'can',\n",
       " 'do',\n",
       " 'agriculture',\n",
       " 'peacefully',\n",
       " '.',\n",
       " 'In',\n",
       " 'the',\n",
       " 'industrial',\n",
       " 'sector',\n",
       " 'also',\n",
       " 'humans',\n",
       " 'and',\n",
       " 'machines',\n",
       " 'are',\n",
       " 'working',\n",
       " 'together',\n",
       " 'to',\n",
       " 'increase',\n",
       " 'production',\n",
       " '.',\n",
       " 'Various',\n",
       " 'types',\n",
       " 'of',\n",
       " 'machines',\n",
       " 'are',\n",
       " 'used',\n",
       " 'in',\n",
       " 'industries',\n",
       " 'such',\n",
       " 'as',\n",
       " 'packing',\n",
       " 'machines',\n",
       " 'loading',\n",
       " 'machine',\n",
       " 'etc',\n",
       " '.',\n",
       " 'humans',\n",
       " 'provide',\n",
       " 'instructions',\n",
       " 'to',\n",
       " 'the',\n",
       " 'machines',\n",
       " 'and',\n",
       " 'maintain',\n",
       " 'the',\n",
       " 'management',\n",
       " 'in',\n",
       " 'the',\n",
       " 'company',\n",
       " '.',\n",
       " 'Soon',\n",
       " 'robots',\n",
       " '[',\n",
       " 'machines',\n",
       " ']',\n",
       " 'will',\n",
       " 'assist',\n",
       " 'doctors',\n",
       " 'with',\n",
       " 'surgeries',\n",
       " '.',\n",
       " 'For',\n",
       " 'instance',\n",
       " 'a',\n",
       " 'doctor',\n",
       " 'at',\n",
       " 'remote',\n",
       " 'location',\n",
       " 'could',\n",
       " 'direct',\n",
       " 'a',\n",
       " 'surgical',\n",
       " 'robot',\n",
       " 'to',\n",
       " 'perform',\n",
       " 'an',\n",
       " 'open',\n",
       " 'heart',\n",
       " 'surgery',\n",
       " '.',\n",
       " 'But',\n",
       " 'the',\n",
       " 'approaches',\n",
       " 'option',\n",
       " 'and',\n",
       " 'decision',\n",
       " 'will',\n",
       " 'be',\n",
       " 'left',\n",
       " 'to',\n",
       " 'experience',\n",
       " 'and',\n",
       " 'wisdom',\n",
       " 'of',\n",
       " 'the',\n",
       " 'doctor',\n",
       " 'not',\n",
       " 'the',\n",
       " 'robot',\n",
       " '.',\n",
       " 'What',\n",
       " 'do',\n",
       " 'you',\n",
       " 'think',\n",
       " 'of',\n",
       " 'machines',\n",
       " 'if',\n",
       " 'they',\n",
       " 'will',\n",
       " 'make',\n",
       " 'humans',\n",
       " 'less',\n",
       " 'or',\n",
       " 'more',\n",
       " 'in',\n",
       " 'the',\n",
       " 'field',\n",
       " 'Machines',\n",
       " 'will',\n",
       " 'push',\n",
       " 'human',\n",
       " 'professionals',\n",
       " 'up',\n",
       " 'the',\n",
       " 'skillset',\n",
       " 'ladder',\n",
       " 'into',\n",
       " 'uniquely',\n",
       " 'human',\n",
       " 'skills',\n",
       " 'such',\n",
       " 'as',\n",
       " 'creativity',\n",
       " 'social',\n",
       " 'abilities',\n",
       " 'empathy',\n",
       " 'and',\n",
       " 'sense',\n",
       " 'making',\n",
       " 'which',\n",
       " 'machines',\n",
       " 'can',\n",
       " 'not',\n",
       " 'automate',\n",
       " '.',\n",
       " 'As',\n",
       " 'a',\n",
       " 'result',\n",
       " 'machines',\n",
       " 'will',\n",
       " 'make',\n",
       " 'the',\n",
       " 'workplace',\n",
       " 'more',\n",
       " 'not',\n",
       " 'less',\n",
       " 'for',\n",
       " 'humans',\n",
       " '.',\n",
       " 'However',\n",
       " 'humans',\n",
       " 'have',\n",
       " 'to',\n",
       " 'learn',\n",
       " 'new',\n",
       " 'skills',\n",
       " 'throughout',\n",
       " 'their',\n",
       " 'lives',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'said',\n",
       " 'that',\n",
       " 'in',\n",
       " 'the',\n",
       " 'future',\n",
       " '80',\n",
       " 'of',\n",
       " 'process',\n",
       " 'oriented',\n",
       " 'tasks',\n",
       " 'will',\n",
       " 'be',\n",
       " 'done',\n",
       " 'by',\n",
       " 'machines',\n",
       " '.',\n",
       " 'Quantitative',\n",
       " 'reasoning',\n",
       " 'tasks',\n",
       " 'will',\n",
       " 'be',\n",
       " 'done',\n",
       " 'approximately',\n",
       " '50',\n",
       " 'by',\n",
       " 'humans',\n",
       " 'and',\n",
       " '50',\n",
       " 'by',\n",
       " 'machines',\n",
       " 'while',\n",
       " 'humans',\n",
       " 'will',\n",
       " 'continue',\n",
       " 'to',\n",
       " 'do',\n",
       " 'more',\n",
       " 'than',\n",
       " '80',\n",
       " 'of',\n",
       " 'cross',\n",
       " 'functional',\n",
       " 'reasoning',\n",
       " 'tasks',\n",
       " '.',\n",
       " 'According',\n",
       " 'to',\n",
       " 'Harvard',\n",
       " 'research',\n",
       " 'machines',\n",
       " 'algorithms',\n",
       " 'can',\n",
       " 'read',\n",
       " 'diagnostic',\n",
       " 'scans',\n",
       " 'with',\n",
       " '92',\n",
       " 'accuracy',\n",
       " '.',\n",
       " 'Humans',\n",
       " 'can',\n",
       " 'do',\n",
       " 'it',\n",
       " 'with',\n",
       " '96',\n",
       " 'accuracy',\n",
       " '.',\n",
       " 'Together',\n",
       " 'it',\n",
       " 'will',\n",
       " 'be',\n",
       " '99',\n",
       " 'accurate',\n",
       " '.',\n",
       " 'Human',\n",
       " 'machine',\n",
       " 'collaboration',\n",
       " 'enables',\n",
       " 'companies',\n",
       " 'to',\n",
       " 'interact',\n",
       " 'with',\n",
       " 'employees',\n",
       " 'and',\n",
       " 'customers',\n",
       " 'in',\n",
       " 'the',\n",
       " 'novel',\n",
       " 'more',\n",
       " 'effective',\n",
       " 'ways',\n",
       " '.',\n",
       " 'Smart',\n",
       " 'machines',\n",
       " 'are',\n",
       " 'helping',\n",
       " 'humans',\n",
       " 'to',\n",
       " 'expand',\n",
       " 'their',\n",
       " 'abilities',\n",
       " 'in',\n",
       " 'three',\n",
       " 'ways',\n",
       " '.',\n",
       " 'They',\n",
       " 'can',\n",
       " 'amplify',\n",
       " 'our',\n",
       " 'cognitive',\n",
       " 'strengths',\n",
       " ';',\n",
       " 'interact',\n",
       " 'with',\n",
       " 'customers',\n",
       " 'and',\n",
       " 'employees',\n",
       " 'to',\n",
       " 'free',\n",
       " 'us',\n",
       " 'from',\n",
       " 'higher',\n",
       " 'level',\n",
       " 'tasks',\n",
       " 'and',\n",
       " 'embody',\n",
       " 'human',\n",
       " 'skills',\n",
       " 'to',\n",
       " 'extend',\n",
       " 'our',\n",
       " 'physical',\n",
       " 'capabilities',\n",
       " '.',\n",
       " 'In',\n",
       " 'the',\n",
       " 'research',\n",
       " 'it',\n",
       " 'was',\n",
       " 'found',\n",
       " 'that',\n",
       " '1',\n",
       " '500',\n",
       " 'companies',\n",
       " 'achieve',\n",
       " 'the',\n",
       " 'most',\n",
       " 'significant',\n",
       " 'performance',\n",
       " 'improvement',\n",
       " 'when',\n",
       " 'humans',\n",
       " 'and',\n",
       " 'machines',\n",
       " 'work',\n",
       " 'together',\n",
       " '.',\n",
       " 'New',\n",
       " 'machine',\n",
       " 'systems',\n",
       " 'have',\n",
       " 'beyond',\n",
       " 'human',\n",
       " 'cognitive',\n",
       " 'abilities',\n",
       " 'which',\n",
       " 'many',\n",
       " 'of',\n",
       " 'us',\n",
       " 'fear',\n",
       " 'could',\n",
       " 'potentially',\n",
       " 'dehumanize',\n",
       " 'the',\n",
       " 'future',\n",
       " 'of',\n",
       " 'work',\n",
       " '.',\n",
       " 'Machines',\n",
       " 'will',\n",
       " 'indeed',\n",
       " 'automate',\n",
       " 'most',\n",
       " 'repetitive',\n",
       " 'and',\n",
       " 'physical',\n",
       " 'tasks',\n",
       " 'and',\n",
       " 'part',\n",
       " 'of',\n",
       " 'quantitative',\n",
       " 'tasks',\n",
       " 'such',\n",
       " 'as',\n",
       " 'programming',\n",
       " 'and',\n",
       " 'even',\n",
       " 'data',\n",
       " 'science',\n",
       " '.',\n",
       " 'According',\n",
       " 'to',\n",
       " 'D.E',\n",
       " 'Shaw',\n",
       " 'Group',\n",
       " 'and',\n",
       " 'professor',\n",
       " 'at',\n",
       " 'the',\n",
       " 'University',\n",
       " 'of',\n",
       " 'Washington',\n",
       " 'explained',\n",
       " 'that',\n",
       " 'as',\n",
       " 'a',\n",
       " 'result',\n",
       " 'of',\n",
       " 'machines',\n",
       " 'there',\n",
       " 'will',\n",
       " 'be',\n",
       " 'more',\n",
       " 'demand',\n",
       " 'for',\n",
       " 'existing',\n",
       " 'jobs',\n",
       " 'and',\n",
       " 'new',\n",
       " 'jobs',\n",
       " 'will',\n",
       " 'be',\n",
       " 'created',\n",
       " 'that',\n",
       " 'are',\n",
       " 'unimaginable',\n",
       " 'today',\n",
       " '.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'similar',\n",
       " 'to',\n",
       " 'how',\n",
       " 'we',\n",
       " 'couldn',\n",
       " 't',\n",
       " 'imagine',\n",
       " 'a',\n",
       " 'web',\n",
       " 'app',\n",
       " 'developer',\n",
       " 'decades',\n",
       " 'ago',\n",
       " 'and',\n",
       " 'now',\n",
       " 'millions',\n",
       " 'make',\n",
       " 'a',\n",
       " 'living',\n",
       " 'doing',\n",
       " 'that',\n",
       " 'today',\n",
       " '.',\n",
       " 'Machines',\n",
       " 'are',\n",
       " 'good',\n",
       " 'at',\n",
       " 'doing',\n",
       " 'tasks',\n",
       " 'with',\n",
       " 'speed',\n",
       " 'precision',\n",
       " 'and',\n",
       " 'accuracy',\n",
       " '.',\n",
       " 'But',\n",
       " 'machines',\n",
       " 'are',\n",
       " 'not',\n",
       " 'very',\n",
       " 'good',\n",
       " 'at',\n",
       " 'responding',\n",
       " 'to',\n",
       " 'unknown',\n",
       " 'situations',\n",
       " 'or',\n",
       " 'making',\n",
       " 'judgments',\n",
       " '.',\n",
       " 'That',\n",
       " 'part',\n",
       " 'will',\n",
       " 'be',\n",
       " 'left',\n",
       " 'to',\n",
       " 'humans',\n",
       " '.',\n",
       " 'Hence',\n",
       " 'the',\n",
       " 'need',\n",
       " 'for',\n",
       " 'both',\n",
       " 'humans',\n",
       " 'and',\n",
       " 'machines',\n",
       " 'will',\n",
       " 'be',\n",
       " 'there',\n",
       " 'in',\n",
       " 'the',\n",
       " 'future',\n",
       " '.',\n",
       " 'Humans',\n",
       " 'and',\n",
       " 'machines',\n",
       " 'have',\n",
       " 'divergent',\n",
       " 'skill',\n",
       " 'sets',\n",
       " 'that',\n",
       " 'when',\n",
       " 'combined',\n",
       " 'can',\n",
       " 'transform',\n",
       " 'the',\n",
       " 'way',\n",
       " 'we',\n",
       " 'work',\n",
       " '.',\n",
       " 'Machines',\n",
       " 'have',\n",
       " 'already',\n",
       " 'infiltrated',\n",
       " 'every',\n",
       " 'aspect',\n",
       " 'of',\n",
       " 'our',\n",
       " 'lives',\n",
       " 'and',\n",
       " 'we',\n",
       " 'must',\n",
       " 'learn',\n",
       " 'to',\n",
       " 'live',\n",
       " 'with',\n",
       " 'them',\n",
       " '.',\n",
       " 'In',\n",
       " 'the',\n",
       " 'future',\n",
       " 'human',\n",
       " 'workers',\n",
       " 'will',\n",
       " 'interact',\n",
       " 'more',\n",
       " 'closely',\n",
       " 'with',\n",
       " 'humans',\n",
       " '.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = word_tokenize(texts)\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10016a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"D:\\lab\\Dataset\\Stopwords_Blackcoffer.txt\", 'r') as file:\n",
    "    data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c567cbef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ERNST\\nYOUNG\\nDELOITTE\\nTOUCHE\\nKPMG\\nPRICEWATERHOUSECOOPERS\\nPRICEWATERHOUSE\\nCOOPERS\\nAFGHANI\\nARIARY\\nBAHT\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d65bfa92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ERNST,YOUNG,DELOITTE,TOUCHE,KPMG,PRICEWATERHOUSECOOPERS,PRICEWATERHOUSE,COOPERS,AFGHANI,ARIARY,BAHT,'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.replace('\\n', ',')\n",
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ef23874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In future upcoming years humans machines work field work . In upcoming days machines human . Machines [ technology ] work humans incapable . Machines partner operate humans . According professor unive'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_texts = \" \".join([i for i in token if i not in data])\n",
    "new_texts[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea392da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length before cleaning:  4505\n",
      "length after cleaning:  2934\n"
     ]
    }
   ],
   "source": [
    "print(\"length before cleaning: \", len(texts))\n",
    "print(\"length after cleaning: \", len(new_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f456147",
   "metadata": {},
   "source": [
    "# Negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc3618a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"D:\\\\lab\\\\Dataset\\\\Negative_words.txt\", 'r') as file:\n",
    "    negative = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2123c4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2-faced\\n2-faces\\nabnormal\\nabolish\\nabominable\\nabominably\\nabominate\\nabomination\\nabort\\naborted\\naborts\\nabrade\\nabrasive\\nabrupt\\nabruptly\\nabscond\\nabsence\\nabsent-minded\\nabsentee\\nabsurd\\nabsurdity\\nabsurdly\\nabsurdness\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative[:206]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28f44c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2-faced,2-faces,abnormal,abolish,abominable,abominably,abominate,abomination,abort,aborted,aborts,abrade,abrasive,abrupt,abruptly,abscond,absence,absent-minded,absentee,absurd,absurdity,absurdly,absurdness,'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative = negative.replace('\\n', ',')\n",
    "negative[:206]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31a272c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['work', 'work', 'human', 'work', 'incapable', 'explained', 'unimaginable', 'work', 'difficult', 'job', 'vice', 'beat', 'make', 'decision', 'service', 'work', 'difficult', 'drones', 'direct', 'heart', 'decision', 'left', 'experience', 'make', 'human', 'human', 'social', 'sense', 'make', 'oriented', 'continue', 'accuracy', 'accuracy', 'accurate', 'effective', 'free', 'human', 'found', 'significant', 'work', 'human', 'fear', 'dehumanize', 'work', 'repetitive', 'explained', 'unimaginable', 'ago', 'make', 'precision', 'accuracy', 'unknown', 'left', 'divergent', 'skill', 'sets', 'work', 'live', 'human']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_texts = word_tokenize(new_texts)\n",
    "negative_words = [i for i in new_texts if i in negative]\n",
    "print(negative_words)\n",
    "len(negative_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b24f011",
   "metadata": {},
   "source": [
    "# Positive words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b003620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a+\\nabound\\nabounds\\nabundance\\nabundant\\naccessable\\naccessible\\nacclaim\\nacclaimed\\nacclamation\\naccolade\\naccolades\\naccommodative\\naccomodative\\naccomplish\\naccomplished\\naccomplishment\\naccomplishments\\naccurate\\naccurately\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"D:\\\\lab\\\\Dataset\\\\Positive_words.txt\", 'r') as file:\n",
    "    positive = file.read()\n",
    "positive[:210]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66ed38c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a+,abound,abounds,abundance,abundant,accessable,accessible,acclaim,acclaimed,acclamation,accolade,accolades,accommodative,accomodative,accomplish,accomplished,accomplishment,accomplishments,accurate,accurately,'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive = positive.replace('\\n',',')\n",
    "positive[:210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc1387e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['future', 'work', 'work', 'human', 'work', 'work', 'flawlessly', 'easier', 'great', 'future', 'working', 'beat', 'future', 'work', 'modern', 'autonomous', 'peacefully', 'working', 'perform', 'open', 'heart', 'wisdom', 'human', 'human', 'empathy', 'future', 'accurate', 'effective', 'helping', 'free', 'human', 'found', 'achieve', 'significant', 'improvement', 'work', 'human', 'fear', 'future', 'work', 'good', 'speed', 'good', 'future', 'skill', 'work', 'live', 'future', 'human']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_words = [i for i in new_texts if i in positive]\n",
    "print(positive_words)\n",
    "len(positive_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b59646d",
   "metadata": {},
   "source": [
    "#### positive Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d0fbab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "pos_score = len(positive_words)\n",
    "print(pos_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a6cc12",
   "metadata": {},
   "source": [
    "#### Negative Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df0766cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    }
   ],
   "source": [
    "neg_score=len(negative_words)\n",
    "print(neg_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84da7ab7",
   "metadata": {},
   "source": [
    "#### Polarity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21e88c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.09"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Polarity_Score = (pos_score - neg_score)/((pos_score + neg_score) + 0.000001)\n",
    "round(Polarity_Score,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "baf323c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words after cleaning : 418\n"
     ]
    }
   ],
   "source": [
    "print(\"number of words after cleaning :\",len(new_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16495ba1",
   "metadata": {},
   "source": [
    "#### Subjectivity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "841713a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Subjectivity_Score = (pos_score + neg_score)/ ((418) + 0.000001)\n",
    "round(Subjectivity_Score,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7c370e",
   "metadata": {},
   "source": [
    "# Analysis of Readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10209a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "787"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "word_tokens = nltk.word_tokenize(texts)\n",
    "No_of_words = len(word_tokens)\n",
    "No_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bfac2ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokens = nltk.sent_tokenize(texts)\n",
    "No_of_sents = len(sent_tokens)\n",
    "No_of_sents "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1576acfe",
   "metadata": {},
   "source": [
    "### Average sentence Length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11d6a7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.89"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Avg_Sents_Length = No_of_words / No_of_sents\n",
    "round(Avg_Sents_Length,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc20ee3d",
   "metadata": {},
   "source": [
    "### Percentage of Complex words\n",
    "Complex words: words with more than 2 syllable are called complex words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eba6a8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of complex words: 116\n",
      "Total number of words: 4505\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import cmudict\n",
    "cmud = cmudict.dict()\n",
    "\n",
    "# Defining a function to count syllables in a word\n",
    "def count_syllables(word):\n",
    "    phonemes = cmud[word.lower()][0] \n",
    "    return len([s for s in phonemes if s[-1].isdigit()])\n",
    "\n",
    "# Identifing complex words\n",
    "w_tokens = [i for i in word_tokens if i in cmud]\n",
    "complex_words = [word for word in w_tokens if count_syllables(word) > 2]\n",
    "\n",
    "# Calculatingnumber of complex words\n",
    "num_complex_words = len(complex_words)\n",
    "\n",
    "print(\"Number of complex words:\", num_complex_words)\n",
    "print(\"Total number of words:\", len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9546dc95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.84"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Perc_of_Complex_words = len(texts) / num_complex_words\n",
    "round(Perc_of_Complex_words,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e948d1",
   "metadata": {},
   "source": [
    "### Fog Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95fb10bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sentence length: 44.0\n"
     ]
    }
   ],
   "source": [
    "# Tokenize each sentence into words\n",
    "words = [word_tokens for sentence in sent_tokens]\n",
    "\n",
    "# Calculate the average sentence length\n",
    "avg_sent_len = sum(No_of_sents for sentence in words) / No_of_sents\n",
    "\n",
    "print(\"Average sentence length:\", avg_sent_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38f5a93b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.13"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fog_index = 0.4 * (avg_sent_len + Perc_of_Complex_words)\n",
    "round(Fog_index,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4aacea",
   "metadata": {},
   "source": [
    "# Average Number of Words Per Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45da1407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.89"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_no_of_words_per_sent = No_of_words / No_of_sents\n",
    "round(avg_no_of_words_per_sent,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d9b493",
   "metadata": {},
   "source": [
    "# Complex Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "75304424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complex word count: 116\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import cmudict\n",
    "cmud = cmudict.dict()\n",
    "\n",
    "# Defining a function to count syllables in a word\n",
    "def count_syllables(word):\n",
    "    phonemes = cmud[word.lower()][0] \n",
    "    return len([s for s in phonemes if s[-1].isdigit()])\n",
    "\n",
    "# Identifing complex words\n",
    "w_tokens = [i for i in word_tokens if i in cmud]\n",
    "complex_words = [word for word in w_tokens if count_syllables(word) > 2]\n",
    "\n",
    "# Calculatingnumber of complex words\n",
    "num_complex_words = len(complex_words)\n",
    "\n",
    "print(\"complex word count:\", num_complex_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ea5188",
   "metadata": {},
   "source": [
    "# Word Count\n",
    "number of words after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4fb0c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8076ff",
   "metadata": {},
   "source": [
    "# Syllable Count Per Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc568045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a word to get syllable: future\n",
      "Number of syllable in a word : 2\n"
     ]
    }
   ],
   "source": [
    "word = input(\"Enter a word to get syllable: \")\n",
    "def count_syllables(word):\n",
    "    phonemes = cmud[word.lower()][0] \n",
    "    return len([s for s in phonemes if s[-1].isdigit()])\n",
    "\n",
    "print(\"Number of syllable in a word :\",count_syllables(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3a18f6",
   "metadata": {},
   "source": [
    "# Personal Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b8e0d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Personal pronoun frequency: {'he': 1, 'they': 3, 'we': 5, 'you': 1, 'it': 4, 'us': 2, 'them': 1}\n",
      "total number of pronouns in a article : 17\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define a regex pattern to match personal pronouns\n",
    "pattern = r'\\b(I|you|he|she|it|we|they|me|him|her|us|them)\\b'\n",
    "\n",
    "# Count the frequency of personal pronouns\n",
    "pronoun_freq = {}\n",
    "for pronoun in re.findall(pattern, texts, re.IGNORECASE):\n",
    "    pronoun = pronoun.lower()\n",
    "    if pronoun in pronoun_freq:\n",
    "        pronoun_freq[pronoun] += 1\n",
    "    else:\n",
    "        pronoun_freq[pronoun] = 1\n",
    "\n",
    "print(\"Personal pronoun frequency:\", pronoun_freq)\n",
    "def returnSum(dict):\n",
    " \n",
    "    sum = 0\n",
    "    for i in pronoun_freq.values():\n",
    "        sum = sum + i\n",
    " \n",
    "    return sum\n",
    "print(\"total number of pronouns in a article :\",returnSum(pronoun_freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fc87f8",
   "metadata": {},
   "source": [
    "# Average Word Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5bde37d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word length: 4.73\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total number of characters in all words\n",
    "total_chars = sum(len(word) for word in word_tokens)\n",
    "\n",
    "avg_word_length = total_chars / No_of_words\n",
    "\n",
    "print(\"Average word length:\", round(avg_word_length,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0be9aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47803d19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
